{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw_9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vw0ZnImhrsh"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc24wTJmiK-I"
      },
      "source": [
        "path_to_file = 'big_text.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXJimV7LiVob",
        "outputId": "81616c8e-8432-4ad9-da5a-d7ce56d0fcbe"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 18379506 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9FitCVNitRo",
        "outputId": "562ac462-ec1a-47c6-e86a-13369f3e78b5"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Так в какой круиз вы собрались?\n",
            "Он называется \"Плавание перерождения\".\n",
            "\"Христианский ежеквартальник\"\n",
            "дал ему высшую оценку,\n",
            "пять терновых венцов.\n",
            "Я бы хотела, чтобы ты\n",
            "поехал со мной, Шелдон.\n",
            "Ну, если бы я поехал, это было бы\n",
            "окончательным подтверждением,\n",
            "что твой Бог может\n",
            "творить чудеса.\n",
            "Ты упускаешь такой шанс.\n",
            "Там будет настоящее веселье.\n",
            "Всё тематическое.\n",
            "Созерцание Ионы и кита.\n",
            "Шведский стол \"Тайная вечеря\".\n",
            "И моё самое любимое:\n",
            "\"Cтреляй с Богом\".\n",
            "Что такое \"Cтреляй с Богом\"?\n",
            "Даже страшно \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwLA83mCi5Ua"
      },
      "source": [
        "text = text + text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KvQG2TqjFxz",
        "outputId": "e825c718-c803-41ac-ecea-20a609c3d1ef"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaBnCm27-hwZ",
        "outputId": "e4a8879c-8cc8-4598-9790-61dfe0c01b80"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\x7f', '\\xa0', '¢', '«', '°', 'º', '»', '×', 'á', 'é', 'ó', '́', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'є', 'і', '\\u200b', '–', '—', '’', '“', '”', '„', '…', '€', '№', '♪']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emTJ4stWjKby"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhCMTKrCAEyK",
        "outputId": "45754fbc-2c00-4afd-9cf9-f3da2e462506"
      },
      "source": [
        "print(idx2char)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n' ' ' '!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/' '0'\n",
            " '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A' 'B'\n",
            " 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T'\n",
            " 'U' 'V' 'W' 'X' 'Y' 'Z' '[' '\\\\' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f'\n",
            " 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x'\n",
            " 'y' 'z' '|' '~' '\\x7f' '\\xa0' '¢' '«' '°' 'º' '»' '×' 'á' 'é' 'ó' '́' 'Ё'\n",
            " 'А' 'Б' 'В' 'Г' 'Д' 'Е' 'Ж' 'З' 'И' 'Й' 'К' 'Л' 'М' 'Н' 'О' 'П' 'Р' 'С'\n",
            " 'Т' 'У' 'Ф' 'Х' 'Ц' 'Ч' 'Ш' 'Щ' 'Ы' 'Ь' 'Э' 'Ю' 'Я' 'а' 'б' 'в' 'г' 'д'\n",
            " 'е' 'ж' 'з' 'и' 'й' 'к' 'л' 'м' 'н' 'о' 'п' 'р' 'с' 'т' 'у' 'ф' 'х' 'ц'\n",
            " 'ч' 'ш' 'щ' 'ъ' 'ы' 'ь' 'э' 'ю' 'я' 'ё' 'є' 'і' '\\u200b' '–' '—' '’' '“'\n",
            " '”' '„' '…' '€' '№' '♪']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Rf7PYejxo4",
        "outputId": "97d3e8a8-b36b-4a2d-e7b3-a98c9c0d3e82"
      },
      "source": [
        "text_as_int[:500]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([125, 138, 148,   1, 140,   1, 148, 138, 148, 152, 147,   1, 148,\n",
              "       154, 157, 146, 145,   1, 140, 165,   1, 155, 152, 139, 154, 138,\n",
              "       149, 146, 155, 166,  32,   0, 121, 151,   1, 151, 138, 145, 165,\n",
              "       140, 138, 143, 156, 155, 169,   1,   3, 122, 149, 138, 140, 138,\n",
              "       151, 146, 143,   1, 153, 143, 154, 143, 154, 152, 144, 142, 143,\n",
              "       151, 146, 169,   3,  15,   0,   3, 128, 154, 146, 155, 156, 146,\n",
              "       138, 151, 155, 148, 146, 147,   1, 143, 144, 143, 148, 140, 138,\n",
              "       154, 156, 138, 149, 166, 151, 146, 148,   3,   0, 142, 138, 149,\n",
              "         1, 143, 150, 157,   1, 140, 165, 155, 162, 157, 168,   1, 152,\n",
              "       160, 143, 151, 148, 157,  13,   0, 153, 169, 156, 166,   1, 156,\n",
              "       143, 154, 151, 152, 140, 165, 159,   1, 140, 143, 151, 160, 152,\n",
              "       140,  15,   0, 137,   1, 139, 165,   1, 159, 152, 156, 143, 149,\n",
              "       138,  13,   1, 161, 156, 152, 139, 165,   1, 156, 165,   0, 153,\n",
              "       152, 143, 159, 138, 149,   1, 155, 152,   1, 150, 151, 152, 147,\n",
              "        13,   1, 131, 143, 149, 142, 152, 151,  15,   0, 120, 157,  13,\n",
              "         1, 143, 155, 149, 146,   1, 139, 165,   1, 169,   1, 153, 152,\n",
              "       143, 159, 138, 149,  13,   1, 167, 156, 152,   1, 139, 165, 149,\n",
              "       152,   1, 139, 165,   0, 152, 148, 152, 151, 161, 138, 156, 143,\n",
              "       149, 166, 151, 165, 150,   1, 153, 152, 142, 156, 140, 143, 154,\n",
              "       144, 142, 143, 151, 146, 143, 150,  13,   0, 161, 156, 152,   1,\n",
              "       156, 140, 152, 147,   1, 108, 152, 141,   1, 150, 152, 144, 143,\n",
              "       156,   0, 156, 140, 152, 154, 146, 156, 166,   1, 161, 157, 142,\n",
              "       143, 155, 138,  15,   0, 125, 165,   1, 157, 153, 157, 155, 148,\n",
              "       138, 143, 162, 166,   1, 156, 138, 148, 152, 147,   1, 162, 138,\n",
              "       151, 155,  15,   0, 125, 138, 150,   1, 139, 157, 142, 143, 156,\n",
              "         1, 151, 138, 155, 156, 152, 169, 163, 143, 143,   1, 140, 143,\n",
              "       155, 143, 149, 166, 143,  15,   0, 109, 155, 170,   1, 156, 143,\n",
              "       150, 138, 156, 146, 161, 143, 155, 148, 152, 143,  15,   0, 124,\n",
              "       152, 145, 143, 154, 160, 138, 151, 146, 143,   1, 115, 152, 151,\n",
              "       165,   1, 146,   1, 148, 146, 156, 138,  15,   0, 131, 140, 143,\n",
              "       142, 155, 148, 146, 147,   1, 155, 156, 152, 149,   1,   3, 125,\n",
              "       138, 147, 151, 138, 169,   1, 140, 143, 161, 143, 154, 169,   3,\n",
              "        15,   0, 115,   1, 150, 152, 170,   1, 155, 138, 150, 152, 143,\n",
              "         1, 149, 168, 139, 146, 150, 152, 143,  27,   0,   3,  36, 156,\n",
              "       154, 143, 149, 169, 147,   1, 155,   1, 108, 152, 141, 152, 150,\n",
              "         3,  15,   0, 130, 156, 152,   1, 156, 138, 148, 152, 143,   1,\n",
              "         3,  36, 156, 154, 143, 149, 169, 147,   1, 155,   1, 108, 152,\n",
              "       141, 152, 150,   3,  32,   0, 111, 138, 144, 143,   1, 155, 156,\n",
              "       154, 138, 162, 151, 152,   1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxdPNouaj02-"
      },
      "source": [
        "text_as_int, text, len(text_as_int), len(text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvVeVpmtj-sO"
      },
      "source": [
        "# TRAIN AND TARGET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ym-hr_j4eu",
        "outputId": "177ca67f-4523-46bd-a2c7-cbc9a815c4fe"
      },
      "source": [
        "# The maximum length sentence you want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Т\n",
            "а\n",
            "к\n",
            " \n",
            "в\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g69cDpkFkMyv",
        "outputId": "485e8364-165f-4620-8862-29bb497e1d69"
      },
      "source": [
        "type(char_dataset)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xoPaf1pkQ30",
        "outputId": "7f978190-4f6a-4bdb-98b9-68be68ef74e2"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Так в какой круиз вы собрались?\\nОн называется \"Плавание перерождения\".\\n\"Христианский ежеквартальник\"\\n'\n",
            "'дал ему высшую оценку,\\nпять терновых венцов.\\nЯ бы хотела, чтобы ты\\nпоехал со мной, Шелдон.\\nНу, если б'\n",
            "'ы я поехал, это было бы\\nокончательным подтверждением,\\nчто твой Бог может\\nтворить чудеса.\\nТы упускаешь'\n",
            "' такой шанс.\\nТам будет настоящее веселье.\\nВсё тематическое.\\nСозерцание Ионы и кита.\\nШведский стол \"Та'\n",
            "'йная вечеря\".\\nИ моё самое любимое:\\n\"Cтреляй с Богом\".\\nЧто такое \"Cтреляй с Богом\"?\\nДаже страшно спраш'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN1KvO55kx5i",
        "outputId": "4bfd6cbe-f862-4f79-8f3c-54ed11eea42e"
      },
      "source": [
        "type(sequences)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OvDw6qZlPTw"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ2jnT0LlmMw"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoQcmx_Gmbf_",
        "outputId": "981edf90-c730-4e5f-8ab6-2679092b94c5"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_VXpUdtmcWw",
        "outputId": "e49af927-60e0-4bca-f3e7-f525da305d5a"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'Так в какой круиз вы собрались?\\nОн называется \"Плавание перерождения\".\\n\"Христианский ежеквартальник\"'\n",
            "Target data: 'ак в какой круиз вы собрались?\\nОн называется \"Плавание перерождения\".\\n\"Христианский ежеквартальник\"\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vk60KdLm6cv",
        "outputId": "561799b3-f0f0-47eb-c4e5-cf379dd1f5aa"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVonyRPvnavf"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 128\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIBMJd0Gnkma"
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eu8FpUNnuEE"
      },
      "source": [
        "class RNNgenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, batch_size):\n",
        "        super(RNNgenerator, self).__init__()\n",
        "        \n",
        "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "                                 \n",
        "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform')\n",
        "                           \n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        emb_x = self.emb(x)\n",
        "        x1 = self.gru1(emb_x)\n",
        "        x = x1\n",
        "        for _ in range(3):\n",
        "            x = self.gru2(x)\n",
        "        #x = self.gru1(x)\n",
        "        x = (x + x1)/2\n",
        "        return self.fc(x)\n",
        "\n",
        "model = RNNgenerator(vocab_size, embedding_dim, BATCH_SIZE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Xpfo5yoa4h"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CSerjWAogXx"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ADoiFZPomo-",
        "outputId": "ba511100-6f3c-4f65-c9e3-8a1ad598e223"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 184) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlpcl8biosoO",
        "outputId": "60ac8d14-736e-4c57-985a-d36392e6126a"
      },
      "source": [
        "example_batch_predictions[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 184), dtype=float32, numpy=\n",
              "array([[ 3.29826480e-06, -7.49483434e-06, -2.75736124e-06, ...,\n",
              "         1.27719495e-05, -4.66533584e-06,  1.08297684e-06],\n",
              "       [ 1.13621118e-05, -1.93204614e-05, -1.51662816e-05, ...,\n",
              "         3.71963724e-05, -2.09677401e-05, -7.10146924e-06],\n",
              "       [ 1.02570648e-05, -2.57531938e-05, -2.63876573e-05, ...,\n",
              "         7.65321311e-05, -5.76569182e-05, -2.31158465e-05],\n",
              "       ...,\n",
              "       [-8.90020281e-04,  2.76823994e-03, -6.08123548e-04, ...,\n",
              "        -1.15653616e-03, -2.94874015e-04, -9.65196450e-05],\n",
              "       [-9.01771826e-04,  2.70880386e-03, -6.88344473e-04, ...,\n",
              "        -1.03848509e-03, -3.65454471e-04, -1.76813177e-04],\n",
              "       [-9.35969932e-04,  2.64841155e-03, -8.01218033e-04, ...,\n",
              "        -9.03029926e-04, -4.24044731e-04, -2.68723554e-04]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC0I1BO6o1xn"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGJ8np6Bo8iX",
        "outputId": "7195edc9-b969-4d4e-8b86-51e1d2b4f68d"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'а Леонардо Нимоя в роли Спока.\\nРазве я смогу спать спокойно,\\nесли в ногах моей кровати будет Закари '\n",
            "\n",
            "Next Char Predictions: \n",
            " '2’виаs„с́ГЧ„*AЕ—°QН0g“Ц@Фг’ЙвzДFхvктЕ…!є[fХш+!иёЭ]tf6УЭйЦ2cieя¢X…еaЫ\\u200b_э:ЮТsаЩШЕZЦомLКwjс4Y,\\xa0лЯ#jя…Ф`'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ_MXh4Qo_Au",
        "outputId": "e72ca93a-6317-476b-ce6b-18d633e80118"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 184)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       5.2148004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12rqHe7bpH_G"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WONuc9jPpLjM"
      },
      "source": [
        "!rm -rf ./training_checkpoints"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dykk4iw0pORt",
        "outputId": "d6c1412f-a144-4fc3-aed3-271e36671fab"
      },
      "source": [
        "!ls ./training_checkpoints"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './training_checkpoints': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEo8mwtapPsv"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=88*3,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsh-KqJMpXYY"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83xkMWBwpY4V",
        "outputId": "13564ebe-fbd0-4291-db59-3fdbbfe53fc0"
      },
      "source": [
        "with tf.device(\"/gpu:0\"):\n",
        "    history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5686/5686 [==============================] - 1366s 239ms/step - loss: 1.4683\n",
            "Epoch 2/20\n",
            "5686/5686 [==============================] - 1362s 239ms/step - loss: 1.2230\n",
            "Epoch 3/20\n",
            "5686/5686 [==============================] - 1361s 239ms/step - loss: 1.1742\n",
            "Epoch 4/20\n",
            "5686/5686 [==============================] - 1364s 240ms/step - loss: 1.1501\n",
            "Epoch 5/20\n",
            "5686/5686 [==============================] - 1362s 239ms/step - loss: 1.1378\n",
            "Epoch 6/20\n",
            "5686/5686 [==============================] - 1362s 239ms/step - loss: 1.1327\n",
            "Epoch 7/20\n",
            "5686/5686 [==============================] - 1361s 239ms/step - loss: 1.1317\n",
            "Epoch 8/20\n",
            "5686/5686 [==============================] - 1361s 239ms/step - loss: 1.1330\n",
            "Epoch 9/20\n",
            "5686/5686 [==============================] - 1360s 239ms/step - loss: 1.1361\n",
            "Epoch 10/20\n",
            "5686/5686 [==============================] - 1361s 239ms/step - loss: 1.1399\n",
            "Epoch 11/20\n",
            "5686/5686 [==============================] - 1357s 238ms/step - loss: 1.1441\n",
            "Epoch 12/20\n",
            "5686/5686 [==============================] - 1358s 239ms/step - loss: 1.1488\n",
            "Epoch 13/20\n",
            "5686/5686 [==============================] - 1357s 238ms/step - loss: 1.1542\n",
            "Epoch 14/20\n",
            "5686/5686 [==============================] - 1360s 239ms/step - loss: 1.1594\n",
            "Epoch 15/20\n",
            "5686/5686 [==============================] - 1360s 239ms/step - loss: 1.1655\n",
            "Epoch 16/20\n",
            "5686/5686 [==============================] - 1365s 240ms/step - loss: 1.1710\n",
            "Epoch 17/20\n",
            "5686/5686 [==============================] - 1366s 240ms/step - loss: 1.1776\n",
            "Epoch 18/20\n",
            "5686/5686 [==============================] - 1365s 240ms/step - loss: 1.1833\n",
            "Epoch 19/20\n",
            "5686/5686 [==============================] - 1367s 240ms/step - loss: 1.1891\n",
            "Epoch 20/20\n",
            "5686/5686 [==============================] - 1366s 240ms/step - loss: 1.1956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Kk-AR-Xgto6o",
        "outputId": "d0da1469-b4dd-4828-a609-f8ddb845a301"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_20'"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU-In6ANttpJ"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO6ukuMFt_cq",
        "outputId": "d1a27a48-d84c-4d74-e72c-3906d463f474"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 128)            23552     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (1, None, 1024)           4722688   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 184)            188600    \n",
            "=================================================================\n",
            "Total params: 30,112,952\n",
            "Trainable params: 30,112,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u15vR1CFuBiv"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 500\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi4SKJw4uFFU",
        "outputId": "015c1e12-4baa-4475-ed63-f204157a71bc"
      },
      "source": [
        "text_ = generate_text(model, start_string=u\"сижу я на стуле \")\n",
        "print(text_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "сижу я на стуле только посмотрю.\n",
            "Да, я тоже пойду.\n",
            "Да, да, я в порядке.\n",
            "Я тоже пойду с тобой.\n",
            "Хорошо.\n",
            "Я поняла. Подожди.\n",
            "Это точно.\n",
            "Потому что я тоже буду делать все, что хочу.\n",
            "Не стоит отвечать на вопросы на вечеринке.\n",
            "Подожди.\n",
            "Как дела?\n",
            "Я не знаю.\n",
            "Ну, что с тобой?\n",
            "Я не знаю.\n",
            "Ну, я не знаю, что на этом советово.\n",
            "Вы знаете кого-нибудь из того,\n",
            "что вы совершили намерение?\n",
            "Она занята.\n",
            "Знаете, я не знал, что вы чувствуете себя по-другому.\n",
            "Да ладно, послушайте.\n",
            "Я имею в виду, вы не сказали, что она будет произносит\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExGzp6fNMAcs",
        "outputId": "7ee67dc2-4cf5-4150-b366-bc5fef0cbdc1"
      },
      "source": [
        "text_ = generate_text(model, start_string=u\"Как Дела? \")\n",
        "print(text_)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Как Дела? Он не в столе.\n",
            "Здесь никогда не получается.\n",
            "Пол Сам пожаловала во время ограбления\n",
            "и открыто настолько приятности.\n",
            "Так что вы сказали Селия, только для того, чтобы подобрать ее.\n",
            "Поэтому я и должна была сделать это по скайпу.\n",
            "После того, как я подумал, что мы сможем купить в адвокатах.\n",
            "У них есть сердце.\n",
            "Может, пойдём туда подойдем?\n",
            "С вами тоже не плохо.\n",
            "Полагаю, она им была на месте.\n",
            "Я не знаю, что она сказала.\n",
            "Ты был правам.\n",
            "Вы знаете их имена.\n",
            "Да, сэр.\n",
            "Знаете, я думал, она сказала мне, что это\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv-amXqgjyiN"
      },
      "source": [
        "\n",
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 200\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    \n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,]\n",
        "    for temp in temperature:\n",
        "        input_eval = [char2idx[s] for s in start_string]\n",
        "        input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "        # Here batch size == 1\n",
        "        model.reset_states()\n",
        "        for i in range(num_generate):\n",
        "            predictions = model(input_eval)\n",
        "            predictions = tf.squeeze(predictions, 0)\n",
        "            # using a categorical distribution to predict the character returned by the model\n",
        "            predictions = predictions / temp\n",
        "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "            # Pass the predicted character as the next input to the model\n",
        "            # along with the previous hidden state\n",
        "            input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "            text_generated.append(idx2char[predicted_id])\n",
        "        \n",
        "    \n",
        "    return (''.join(text_generated))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdOcs5bKj--T",
        "outputId": "4a652a25-e346-4acc-dbad-b3a82eee1562"
      },
      "source": [
        "text_ = generate_text(model, start_string=u\"Гулять пойдешь? \")\n",
        "print(text_)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Я пойду на поезд.\n",
            "Может быть, вы знаете его имя?\n",
            "Нет, нет. Вы не можете помочь мне.\n",
            "Пожалуйста, не прикасайтесь.\n",
            "Полагаю, вы понимаете.\n",
            "Вы не можете сказать мне об этом.\n",
            "Вы не понимаете, что я должен Я пойду с тобой.\n",
            "Она просто хочет сказать, что я не против.\n",
            "Почему ты не сказал «навсегда\"?\n",
            "Ну, я не знаю.\n",
            "Я не знаю.\n",
            "Я не знаю.\n",
            "Я не знаю, что сказать.\n",
            "Я не знаю, что сказать.\n",
            "Не понимаю, почему ты нЯ бы не смог тебе помочь.\n",
            "Я собирался сказать ему, что я понял.\n",
            "Я поняла.\n",
            "Я просто хочу помочь тебе.\n",
            "Ты ведь понимаешь, как он умер?\n",
            "Ну, я не знаю, что ты имеешь в виду.\n",
            "Я не могу поверить, что он былЯ бы не справился.\n",
            "Я не могу поверить, что она не захочет быть с ней.\n",
            "Ты же знаешь, что она его вернула?\n",
            "Я сказала тебе не поговорить с тобой.\n",
            "Я не знаю, что происходит.\n",
            "Я слышал, что вы были на семейПойду позволю своему разговору.\n",
            "Ты серьезно? Ты закончишь?\n",
            "Нет, я слышал о своих причинах.\n",
            "Я не могу поверить, что все в порядке.\n",
            "Я не собираюсь подтвержден искать тебя следующие вещи.\n",
            "Отлично. ОткудаЯ должна была сделать это.\n",
            "Посмотри на меня.\n",
            "Я не понимаю, почему ты не слышал убийцам девушки.\n",
            "Меня бросили в машине,\n",
            "и она помогала мне подарить вас обоих.\n",
            "Так и есть.\n",
            "Но как она там была ребенком.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGbS_u9iE1-E"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OOIiJ4lE38P",
        "outputId": "3046a8bc-2ec2-441f-9f00-27852ea8126e"
      },
      "source": [
        "text = text.split('\\n')\n",
        "text"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Так в какой круиз вы собрались?',\n",
              " 'Он называется \"Плавание перерождения\".',\n",
              " '\"Христианский ежеквартальник\"',\n",
              " 'дал ему высшую оценку,',\n",
              " 'пять терновых венцов.',\n",
              " 'Я бы хотела, чтобы ты',\n",
              " 'поехал со мной, Шелдон.',\n",
              " 'Ну, если бы я поехал, это было бы',\n",
              " 'окончательным подтверждением,',\n",
              " 'что твой Бог может',\n",
              " 'творить чудеса.',\n",
              " 'Ты упускаешь такой шанс.',\n",
              " 'Там будет настоящее веселье.',\n",
              " 'Всё тематическое.',\n",
              " 'Созерцание Ионы и кита.',\n",
              " 'Шведский стол \"Тайная вечеря\".',\n",
              " 'И моё самое любимое:',\n",
              " '\"Cтреляй с Богом\".',\n",
              " 'Что такое \"Cтреляй с Богом\"?',\n",
              " 'Даже страшно спрашивать.',\n",
              " 'О, это что-то с чем-то.',\n",
              " 'Ты пишешь свои грехи',\n",
              " 'на тарелочках,',\n",
              " 'их запускают в воздух,',\n",
              " 'а ты разносишь их',\n",
              " 'из ружья 12-го калибра,',\n",
              " 'заряженного всепрощением',\n",
              " 'нашего Господа.',\n",
              " 'Если честно, мам, я удивлен,',\n",
              " 'насколько продвинутые взгляды',\n",
              " 'у вашей группы - отправляетесь',\n",
              " 'в море и не боитесь свалиться с края Земли.',\n",
              " 'Допустим,',\n",
              " 'если бы на борту был Шелли,',\n",
              " 'он написал бы',\n",
              " 'на своей тарелочке: \"Умник\",',\n",
              " 'и потом - \"бам!\"',\n",
              " 'Бог дал и Бог взорвал.',\n",
              " 'Ну, мам,',\n",
              " 'согласно моему графику',\n",
              " 'наших выходных',\n",
              " 'веселье начинается с',\n",
              " 'жареного цыпленка.',\n",
              " 'Звучит аппетитно.',\n",
              " 'Отлично. Потому что у меня есть всё,',\n",
              " 'чтобы ты его приготовила.',\n",
              " 'О, ты просто пальчики оближешь!',\n",
              " 'Из-за жареного цыпленка моей мамы',\n",
              " 'нам пришлось купить папе',\n",
              " 'самый большой гроб.',\n",
              " 'Шелдон, твоя мама только с самолёта.',\n",
              " 'Она не хочет готовить.',\n",
              " 'Конечно же, хочет.',\n",
              " 'Готовить для меня это её',\n",
              " 'способ сказать: \"Я люблю тебя\".',\n",
              " 'А готовить, когда она слишком',\n",
              " 'устала, чтобы готовить,',\n",
              " 'это её способ сказать:',\n",
              " '\"Я в самом деле люблю тебя\".',\n",
              " 'Вообще-то, Шелдон, я бы не',\n",
              " 'отказалась сходить перекусить.',\n",
              " 'А это не испортит нам аппетит',\n",
              " 'перед цыплёнком,',\n",
              " 'которого ты сделаешь?',\n",
              " 'Ладно, решено, идём.',\n",
              " 'Вы любите суши?',\n",
              " 'На нашей улице есть',\n",
              " 'отличное местечко.',\n",
              " 'Никогда их не ела,',\n",
              " 'но совсем не вредно',\n",
              " 'попробовать что-нибудь новенькое.',\n",
              " 'Вообще-то пробовать что-нибудь',\n",
              " 'новенькое очень вредно.',\n",
              " 'Именно поэтому лекарства и',\n",
              " 'косметику испытывают',\n",
              " 'на кроликах.',\n",
              " 'Шелдон, ты говоришь, как сумасшедший.',\n",
              " 'На самом деле, я проверяла',\n",
              " 'его в детстве.',\n",
              " 'Доктор сказал, что он в порядке.',\n",
              " 'Я же говорил.',\n",
              " 'Хотя я очень жалею, что',\n",
              " 'мы не обследовались',\n",
              " 'ещё у того специалиста в Хьюстоне.',\n",
              " '\"Теория Большого Взрыва\"',\n",
              " '\"Откровение ринита\"',\n",
              " 'Оригинальные субтитры: addic7ed.com',\n",
              " 'Перевод: notabenoid.com',\n",
              " 'Милости просим!',\n",
              " '<i>(по-японски)</i>',\n",
              " 'Хватит кричать!',\n",
              " 'Меня это не радует.',\n",
              " 'А когда последний раз',\n",
              " 'тебя что-то радовало?',\n",
              " 'Когда надеялся на',\n",
              " 'жареного цыплёнка.',\n",
              " 'Потрясающе.',\n",
              " 'У нас в кафе на четвертом',\n",
              " 'шоссе подают суши,',\n",
              " 'но там это просто рыбные',\n",
              " \"палочки с порцией Uncle Ben's.\",\n",
              " 'Они записывают их в меню',\n",
              " 'кунгфу-буквами, но  это',\n",
              " 'не делает их суши.',\n",
              " 'Э... Кунгфу-буквы - это не',\n",
              " 'очень политкорректно.',\n",
              " 'О, а я думала, что нельзя',\n",
              " 'говорить \"китаёза\".',\n",
              " 'Да-да, и так тоже.',\n",
              " 'Ну, Шелли, как там',\n",
              " 'у вас с твоей подругой Эми',\n",
              " 'ты же не возражаешь, что мама',\n",
              " 'проявит немного любопытства?',\n",
              " 'На самом деле, на фронте Эми',\n",
              " 'есть большие новости.',\n",
              " 'Она исследует',\n",
              " 'нейробиологию привыкания',\n",
              " 'у низших животных.',\n",
              " 'Ей осталось вот столько, чтобы',\n",
              " 'подсадить морскую звезду на кокаин.',\n",
              " 'Можешь мне сказать, что',\n",
              " 'происходит между ними?',\n",
              " 'Это как с Лохнесским чудовищем.',\n",
              " 'Может, оно есть, а может, и нет.',\n",
              " 'Наверное, мы никогда не узнаем.',\n",
              " 'Но иногда интересно попугать',\n",
              " 'себя, размышляя над этим.',\n",
              " 'А у тебя как дела на дамском фронте?',\n",
              " 'Я слышала, у тебя что-то вроде',\n",
              " 'отношений на большом расстоянии.',\n",
              " 'Да, с сестрой Раджа.',\n",
              " 'Всё непросто.',\n",
              " 'Она в Индии.',\n",
              " 'И её родители не в восторге, что',\n",
              " 'она встречается с кем-то белым.',\n",
              " 'О, забавный поворот, да?',\n",
              " 'Никогда не думаешь, что',\n",
              " 'может быть наоборот.',\n",
              " 'Не форсируй события.',\n",
              " 'Ты должен понять, действительно',\n",
              " 'ли у вас отношения,',\n",
              " 'или ты просто называешь их так.',\n",
              " 'Это как в поговорке:',\n",
              " '\"Кошка может родить котят и в печке,',\n",
              " 'но от этого они не станут пирожками.\"',\n",
              " 'Это напомнило мне',\n",
              " 'другую поговорку:',\n",
              " 'Ты можешь обмазать',\n",
              " 'цыплёнка жиром,',\n",
              " 'но не можешь заставить',\n",
              " 'свою мать пожарить его.',\n",
              " 'Шелдон, еще раз пристанешь',\n",
              " 'ко мне с этим цыпленком,',\n",
              " 'Я отшлепаю тебя прямо здесь,',\n",
              " 'в этом ресторане.',\n",
              " 'Прошу, пристань.',\n",
              " 'Ради меня.',\n",
              " 'Миссис Купер, как вам суши?',\n",
              " 'Понравилось.',\n",
              " 'Вот только было бы лучше,',\n",
              " 'если бы их приготовили.',\n",
              " 'И если бы они были мясом.',\n",
              " 'Шелдон, когда ваш домовладелец',\n",
              " 'собирается починить лифт?',\n",
              " 'Не знаю.',\n",
              " 'Мы недавно обсуждали возможность',\n",
              " 'переделать его в ракетную шахту.',\n",
              " 'Ваш сын считает,',\n",
              " 'что нам необходимо нанести упреждающий удар по Бербанку.',\n",
              " 'Ударим по ним, пока они не ударили по нам.',\n",
              " 'Эй, смотрите кто у нас тут.',\n",
              " 'Радж, ты что делаешь?',\n",
              " 'Я не смог найти вас,',\n",
              " 'поэтому купил себе 6 новых друзей.',\n",
              " 'Трое, увы, уже мертвы.',\n",
              " 'Мама, ты помнишь Раджа?',\n",
              " '- Раджеш, моя мама.',\n",
              " '- Конечно.',\n",
              " 'Миссис Купер. Очень рад снова видеть вас.',\n",
              " 'И я рада тебя видеть.',\n",
              " 'Я думала, это у наших индейцев',\n",
              " 'бывают проблемы с алкоголем.',\n",
              " 'Так тоже не говорят.',\n",
              " 'Я составлю вам список.',\n",
              " 'О, ты достойный белый человек.',\n",
              " 'Итак, Радж, какую боль ты пытаешься',\n",
              " 'заглушить алкоголем?',\n",
              " '- Никакую. Я в порядке.',\n",
              " '- Неужели?',\n",
              " 'Так-то лучше.',\n",
              " 'А теперь скажи, что тебя беспокоит.',\n",
              " 'Я так одинок.',\n",
              " 'Ах да, рождаемся в одиночестве',\n",
              " 'и умираем в одиночестве.',\n",
              " 'Такова трагедия человеческой жизни.',\n",
              " 'А теперь Радж,',\n",
              " 'прошу извинить мою мать,',\n",
              " 'она хочет испечь ореховый пирог,',\n",
              " 'который будет настолько хорош,',\n",
              " 'что я почти забуду,',\n",
              " 'как она напортачила',\n",
              " 'с жареным цыплёнком.',\n",
              " 'Шелдон, твоему другу плохо.',\n",
              " 'Что мы делаем, когда кому-нибудь плохо?',\n",
              " 'Предлагаем им горячий напиток.',\n",
              " 'А когда они пьяны в стельку,',\n",
              " 'какой напиток мы должны предложить?',\n",
              " 'Кофе.',\n",
              " 'А потом что мы делаем?',\n",
              " 'Теперь слушай меня.',\n",
              " 'Я знаю, что тебе кажется, что',\n",
              " 'ты не можешь никого найти,',\n",
              " 'но на каждый ключ существует свой замок.',\n",
              " 'У нас была девушка,',\n",
              " 'работала в Уол-Марте.',\n",
              " 'Высокая, высокая девушка.',\n",
              " 'Она могла охотиться на гусей даже с граблями.',\n",
              " 'Думали, она никогда',\n",
              " 'не найдёт мужчину, но однажды,',\n",
              " 'ты не поверишь,',\n",
              " 'в город приехали \"Странники из Гарлема\".',\n",
              " 'Короче говоря,',\n",
              " 'теперь эта женщина ',\n",
              " 'ездит по миру',\n",
              " 'с полупрофессиональными',\n",
              " 'баскетболистами',\n",
              " 'и двумя прелестными малышами',\n",
              " 'смешанной расы.',\n",
              " 'Я не очень много понял,',\n",
              " 'из-за вашего акцента,',\n",
              " 'но общий тон был утешающий,',\n",
              " 'и, в общем, теперь мне лучше.',\n",
              " 'Я не дождусь орехового пирога, да?',\n",
              " 'Хочешь печенюшек?',\n",
              " '- С двойной начинкой?',\n",
              " '- Нет, обычные.',\n",
              " 'Браво. Пинай лежачего.',\n",
              " 'Я рад, что мы наконец-то',\n",
              " 'делаем что-то вместе,',\n",
              " 'только ты и я.',\n",
              " 'Конечно. Единственное, чего',\n",
              " 'действительно не хватает',\n",
              " 'во время отпуска - это стирки.',\n",
              " 'Осторожней, ты льешь слишком',\n",
              " 'много смягчителя.',\n",
              " 'Ты же знаешь, если моя одежда',\n",
              " 'слишком мягкая, меня клонит в сон.',\n",
              " 'Да, как в старые времена.',\n",
              " 'Я стираю, а ты рядом критикуешь.',\n",
              " 'Здорово, правда?',\n",
              " 'Миссис Купер.',\n",
              " '- Привет!',\n",
              " '- Здравствуй, дорогая.',\n",
              " 'Шелдон, ты не говорил мне, ',\n",
              " 'что приедет твоя мама.',\n",
              " 'Это было в моей еженедельной рассылке.',\n",
              " 'Прямо между',\n",
              " '\"Свекольный сезон наконец-то настал\"',\n",
              " 'и \"Ой-ёй, красный стул из-за свёклы',\n",
              " 'может вызвать страх, что у вас рак.\"',\n",
              " 'Ну, как у тебя дела?',\n",
              " 'Хорошо, хорошо.',\n",
              " 'Слышала, что у Леонарда новая девушка.',\n",
              " 'Как ты с этим справляешься?',\n",
              " 'Неплохо. Знаете, уже ведь',\n",
              " 'столько времени прошло.',\n",
              " 'Для меня все закончилось.',\n",
              " 'Позволь спросить, теперь, когда все закончилось,',\n",
              " 'ты носишь ЭТО?',\n",
              " 'Ну, он очень классный.',\n",
              " 'Этот топ уже окупил себя',\n",
              " 'бесплатными напитками,',\n",
              " 'наверное, раз десять.',\n",
              " 'Да, денежные средства Пенни в',\n",
              " 'большинстве своем завязаны на',\n",
              " 'беспорядочности сексуальных связей.',\n",
              " 'Дорогая, ты не думаешь,',\n",
              " 'что причина, по которой, ты не можешь',\n",
              " 'начать серьёзные отношения',\n",
              " 'заключается в том, что ты разрешаешь им покататься на американских горках',\n",
              " 'не покупая билет?',\n",
              " 'Они не всегда катаются',\n",
              " 'на карусели.',\n",
              " 'Иногда они лишь крутятся рядом с чашечкой.',\n",
              " 'Я хочу сегодня прогуляться,',\n",
              " 'это не будет дико,',\n",
              " 'если я попрошу вас оценить,',\n",
              " 'что я надену?',\n",
              " 'О, нет, совсем не дико.',\n",
              " 'И не казни себя.',\n",
              " 'В твоём возрасте меня можно',\n",
              " 'было получить за поездку на машине',\n",
              " 'и бутылку земляничного вина.',\n",
              " 'Этого не будет в рассылке',\n",
              " 'за эту неделю.',\n",
              " 'А этой весной я отправлюсь',\n",
              " 'на Международную Космическую Станцию.',\n",
              " 'Ох, надо же, путь на небеса.',\n",
              " 'Если хочешь жить там вечно,',\n",
              " 'у меня есть для тебя книга.',\n",
              " 'Спасибо, но я каждый год смотрю',\n",
              " 'рождественские выпуски',\n",
              " 'Чарли Брауна,',\n",
              " 'так что я в курсе.',\n",
              " 'Могу поспорить, твоя мама',\n",
              " 'очень гордится тобой.',\n",
              " 'Она говорит, что если я не откажусь,',\n",
              " 'она объявит голодовку.',\n",
              " 'Понадобятся годы, прежде чем',\n",
              " 'ей будет угрожать опасность, но всё же.',\n",
              " 'Я знаю, как мы завтра развлечемся, мам.',\n",
              " 'Я поведу тебя',\n",
              " 'на лекцию Сола Перлмуттера',\n",
              " 'о его работе по космологии,',\n",
              " 'получившей нобелевскую премию.',\n",
              " 'И что самое лучшее,',\n",
              " 'после нее будут вопросы и ответы,',\n",
              " 'Я проработал парочку вопросов,',\n",
              " 'на которые он не найдёт ответов.',\n",
              " 'Не знаю, Шелли.',\n",
              " 'Я думаю мы могли бы осмотреть достопримечательности.',\n",
              " 'Какие достопримечательности могут быть лучше твоего ребенка',\n",
              " 'огорошившего нобелевского лауреата?',\n",
              " 'Да ладно, Шелдон,',\n",
              " 'мы покажем твоей маме',\n",
              " 'надпись \"Голливуд\",',\n",
              " 'музей восковых фигур,',\n",
              " 'Аллею славы,',\n",
              " 'О, может, пройдемся',\n",
              " 'по Родео-Драйв.',\n",
              " 'Ну, я не могу потратить',\n",
              " '12 тысяч на сумочку,',\n",
              " 'но почему бы не посмотреть на тех,',\n",
              " 'кто может, с праведным осуждением.',\n",
              " 'Что скажешь?',\n",
              " 'Что скажу?',\n",
              " 'Скажу, что хватит вам портить',\n",
              " 'приезд моей мамы',\n",
              " 'своими суши, своими печалями',\n",
              " 'и своей развратной одеждой.',\n",
              " 'Хватит!',\n",
              " 'Он говорил не о твоей одежде,',\n",
              " 'с твоей всё нормально.',\n",
              " 'Это изумительно.',\n",
              " 'Секрет блинчиков в свином жире.',\n",
              " 'Я все на нем готовлю.',\n",
              " 'Все? Вы не беспокоитесь о своем здоровье?',\n",
              " 'Ох, доктора постоянно меняют свое мнение.',\n",
              " 'На одной неделе свиное сало для вас вредно.',\n",
              " 'А на следующей вам не хватает его.',\n",
              " 'Доброе утро, Шелли.',\n",
              " 'Мам, я хочу извиниться за свое',\n",
              " 'вчерашнее поведение.',\n",
              " '- Извинение принято.',\n",
              " '- Отлично.',\n",
              " 'Тебе понравится лекция Перлмуттера.',\n",
              " 'Слушай, он будет утверждать,',\n",
              " 'что Вселенной больше',\n",
              " '6 тысяч лет, но, думаю,',\n",
              " 'в эти моменты ты можешь заткнуть уши',\n",
              " 'и напевать «О, благодать».',\n",
              " 'Я всё равно собираюсь пойти',\n",
              " 'с твоими друзьями.',\n",
              " 'Но я же извинился.',\n",
              " 'И это было трудно, потому что',\n",
              " 'я не сделал ничего плохого.',\n",
              " 'Шелли, я вдоволь насиделась с тобой',\n",
              " 'в пыльных лекториях,',\n",
              " 'когда ты рос.',\n",
              " 'Я хочу осмотреть достопримечательности.',\n",
              " 'Так почему бы тебе не съесть',\n",
              " 'пару блинчиков,',\n",
              " 'одеться и пойти с нами?',\n",
              " 'Я не пойду, и ты не сможешь',\n",
              " 'заставить меня.',\n",
              " 'Ты прав. Не смогу.',\n",
              " 'Хорошего дня.',\n",
              " 'Я буду стоять здесь,',\n",
              " 'пока ты не передумаешь.',\n",
              " 'Ну, тогда ты простоишь здесь весь день.',\n",
              " 'Я только захвачу блинчики',\n",
              " 'и отползу вон туда.',\n",
              " 'Не могу поверить, что моя собственная',\n",
              " 'мать бросает меня.',\n",
              " 'Я не бросаю тебя.',\n",
              " 'Шелдон, бросить тебя - это оставить в корзине',\n",
              " 'на пороге церкви.',\n",
              " 'Я собираюсь в Голливуд, а также поблагодарить',\n",
              " 'воскового Рональда Рейгана',\n",
              " 'за службу на благо нашей страны.',\n",
              " 'Похоже, мы находимся на распутье',\n",
              " 'наших отношений, мама.',\n",
              " 'Ну, думаю, да.',\n",
              " 'Извиняюсь. Сиропчик.',\n",
              " 'Ладно, мама.',\n",
              " 'Когда будешь в музее Рипли',\n",
              " '\"Хотите верьте, хотите нет\",',\n",
              " 'если у них будет экспонат с матерью,',\n",
              " 'упустившей шанс',\n",
              " 'провести день с самым',\n",
              " 'замечательным сыном в мире,',\n",
              " 'поверь, потому что это правда.',\n",
              " 'Я ещё не...',\n",
              " 'Лекция была пустой тратой времени.',\n",
              " 'Я делал более точные диаграммы',\n",
              " 'расширения ранней вселенной',\n",
              " 'на стене в яслях',\n",
              " 'содержимым своего подгузника.',\n",
              " 'Ты заболел?',\n",
              " 'Нет, просто у меня аллергия на людей,',\n",
              " 'которые получают Нобелевскую премию',\n",
              " 'безо всяких оснований.',\n",
              " 'Шелдон, может ли твоё гадкое настроение,',\n",
              " 'или, выражаясь клиническим термином, стервозность,',\n",
              " 'быть следствием того, что твоя мама',\n",
              " 'занята не только одним тобой?',\n",
              " 'Нет. Или выражаясь клиническим термином,',\n",
              " '\"нетушки\".',\n",
              " 'Уверен? Связь дитя-мать это',\n",
              " 'базовый элемент психологии приматов.',\n",
              " 'Ох, ну вот опять.',\n",
              " 'Ты всегда всё сводишь к обезьянам.',\n",
              " 'Одни обезьяны, обезьяны, обезьяны.',\n",
              " 'Шелдон, мы все животные.',\n",
              " 'И допустим, некоторые твои черты  исключительны,',\n",
              " 'но когда дело касается эмоций и взаимоотношений,',\n",
              " 'ты такой же, как и все.',\n",
              " 'Ты пытаешься предположить,',\n",
              " 'что мои эмоциональные проблемы',\n",
              " 'не отличаются от проблем',\n",
              " 'обычного глупца?',\n",
              " 'Вообще-то, есть исследования,',\n",
              " 'доказывающие, что чем ',\n",
              " 'человек глупее,',\n",
              " 'тем ему проще жить',\n",
              " ' в эмоциональном плане.',\n",
              " 'Ты уверен, что не простыл?',\n",
              " 'О, да, обычная простуда.',\n",
              " 'Как у всех.',\n",
              " 'Тебе бы понравилось, да?',\n",
              " 'Оу, а здесь мило.',\n",
              " 'Ну для этих ваших перебирателей четок.',\n",
              " 'Миссис Купер, мы говорим \"католики\", а не \"перебиратели четок\".',\n",
              " 'Боже мой, я удивляюсь как вы тут в Калифорнии',\n",
              " 'вообще умудряетесь говорить.',\n",
              " 'Это, наверное, самый худший',\n",
              " 'тур по Голливуду всех времен.',\n",
              " 'Что тут поделать?',\n",
              " 'Она хотела посмотреть церкви.',\n",
              " 'Эй, тут же есть вино, правда?',\n",
              " 'Ни у кого из наших богов',\n",
              " 'нет такого пресса.',\n",
              " 'Ага. Это последний еврей,',\n",
              " 'который делал упражнения.',\n",
              " 'И посмотри, куда это его привело.',\n",
              " 'Эй, раз уж мы здесь,',\n",
              " 'почему бы нам не помолиться?',\n",
              " 'Пусть эта церковь чуть-чуть',\n",
              " 'побудет церковью.',\n",
              " 'О, не думаю, что нам стоит...',\n",
              " 'Это просто.',\n",
              " 'Я покажу вам.',\n",
              " 'Господь, это Мэри Купер.',\n",
              " 'Обращаюсь к тебе из Гоморры в Калифорнии.',\n",
              " 'Хочу поблагодарить тебя',\n",
              " 'за мою радость и счастье -',\n",
              " 'маленького Шелли.',\n",
              " 'И ещё за то, что даешь мне силы',\n",
              " 'не огреть его моей Библией.',\n",
              " 'Так, Пенни, твоя очередь.',\n",
              " 'Ладно, эм...',\n",
              " 'Привет, Бог.',\n",
              " 'Как житуха?',\n",
              " 'Эм. Я в порядке, но ты бы очень',\n",
              " 'помог моей семье,',\n",
              " 'если бы смог заставить моего',\n",
              " 'братца перестать варить дурь.',\n",
              " 'Только без копов. Помягче.',\n",
              " 'И еще она слишком налегает',\n",
              " 'на \"полюби ближнего своего\".',\n",
              " 'Ты бы мог поболтать с ней,',\n",
              " 'как тогда с Марией Магдаленой.',\n",
              " 'Леонард, теперь ты.',\n",
              " 'Вассерман, ты готовься.',\n",
              " 'Ладно. Не знаю...',\n",
              " 'Наверное, уже поздновато',\n",
              " 'просить сделать меня повыше.',\n",
              " 'Эм... если бы ты мог помочь',\n",
              " 'мне с моей девушкой.',\n",
              " 'Она постоянно в Индии.',\n",
              " 'Было бы здорово.',\n",
              " 'Слышал? Девчачьи заботы.',\n",
              " 'Выходит, мы оба ошибались на этот счет.',\n",
              " 'Что у тебя?',\n",
              " 'У меня? Нет, спасибо,',\n",
              " 'у меня всё хорошо.',\n",
              " 'Я всего лишь пытаюсь',\n",
              " 'не сгореть в адском пламени.',\n",
              " 'Раджеш?',\n",
              " 'Он говорит, что ему трудно сбросить эту',\n",
              " 'последнюю пару килограмм.',\n",
              " 'Ха, я думаю, ты мог попросить решить проблему \"разговоров с девушками\"',\n",
              " 'Нет, у тебя только одно желание.',\n",
              " 'Только посмотрите на нас.',\n",
              " 'Я, глубокоуважаемый физик.',\n",
              " 'Из тех великих умов, ',\n",
              " 'которых всего',\n",
              " 'один-два на поколение.',\n",
              " 'Ты - обычный человек,',\n",
              " 'которому надоело ',\n",
              " 'торговать на бирже,',\n",
              " 'или продавать пылесосы,',\n",
              " 'или гуталин.',\n",
              " 'Но где-то глубоко внутри...',\n",
              " 'окажется, что мы - ',\n",
              " 'две горошки на ложке.',\n",
              " 'Один горошек обычный,',\n",
              " 'а второй - из тех, которых',\n",
              " 'один-два на поколение.',\n",
              " 'Дождь.',\n",
              " 'Дождь уравнивает всех.',\n",
              " 'Омывая как светлые головы,',\n",
              " 'так и прочие головы тоже.',\n",
              " 'Хлыщ.',\n",
              " 'О, Миссис Купер,',\n",
              " 'так вкусно пахнет!',\n",
              " 'Возьми на заметку, дорогая.',\n",
              " 'Лучший способ заполучить',\n",
              " 'мужчину - это',\n",
              " 'плавленый сыр и грибной соус.',\n",
              " 'Он умрет в 50, но любовь',\n",
              " 'его будет настоящей.',\n",
              " 'Мне нужна салфетка.',\n",
              " 'Эта уже мокрая.',\n",
              " 'Держи.',\n",
              " 'Спасибо. Да, мы сегодня',\n",
              " 'много поняли.',\n",
              " 'Мы с тобой, во многом,',\n",
              " 'не по уму и чему-то важному,',\n",
              " 'конечно, мы - одинаковые.',\n",
              " 'Милый, ты заболел?',\n",
              " 'Надеюсь, ведь если это норма,',\n",
              " 'тогда вообще не стоит жить.',\n",
              " 'О, сладенький, ты весь',\n",
              " 'горишь.',\n",
              " '- Тебя надо уложить в постельку.',\n",
              " '- Хорошо.',\n",
              " 'Не волнуйся. Мамочка здесь,',\n",
              " 'она позаботится о своем малыше.',\n",
              " 'И чтобы внести ясность:',\n",
              " 'только о своём малыше,',\n",
              " 'а не обо всех этих людях.',\n",
              " 'Конечно.',\n",
              " 'А можно мне чаю с мёдом',\n",
              " 'и гренку без корочки?',\n",
              " 'Тебе можно все, ',\n",
              " 'что захочешь.',\n",
              " 'Спасибо, Мамуль.',\n",
              " 'Ты лучше всех.',\n",
              " 'Ох, когда я натирала тебя',\n",
              " 'мазью в последний раз,',\n",
              " 'у тебя на груди ',\n",
              " 'не было волос.',\n",
              " 'Знаю, они проросли ',\n",
              " 'за последний год.',\n",
              " 'В этот раз я провел с тобой',\n",
              " 'так мало времени.',\n",
              " 'И кто в этом виноват?',\n",
              " 'Шелли, тебе уже давно',\n",
              " 'не восемь лет.',\n",
              " 'Нам пора общаться',\n",
              " 'по-взрослому.',\n",
              " 'Нет, не пора.',\n",
              " 'То, как мы общаемся,',\n",
              " 'меня устраивает.',\n",
              " 'Милый, но ты же',\n",
              " 'уже совсем взрослый.',\n",
              " 'Или, возможно, я - ',\n",
              " 'родоначальник нового вида,',\n",
              " 'который живет сотни лет,',\n",
              " 'и это значит, что я все',\n",
              " 'еще совсем малыш.',\n",
              " 'Ох, всё-таки нужно было',\n",
              " 'отвезти тебя в Хьюстон.',\n",
              " 'Это значит, что ты не споешь',\n",
              " 'мне песенку про котёнка?',\n",
              " 'Нет, я всегда буду петь',\n",
              " 'тебе про котёнка.',\n",
              " 'Тёплый, пушистый,',\n",
              " 'Котёнок спит...',\n",
              " 'Миссис Купер, мы должны были',\n",
              " 'вытащить пирог из духовки?',\n",
              " 'Пошел вон!',\n",
              " 'Ну, это было грубо.',\n",
              " 'Знаю, но он хотел как лучше.',\n",
              " 'Счастливый котёнок, сонный котёнок...',\n",
              " 'Пытаешься сачковать, мам?',\n",
              " 'С самого начала.',\n",
              " 'Вот об этом я и говорю.',\n",
              " 'Тёплый, пушистый, ',\n",
              " 'Котёнок спит...',\n",
              " 'Оригинальные субтитры: www.addic7ted.com, elderman',\n",
              " 'Перевод: notabenoid.com',\n",
              " 'Переведено на сайте www.notabenoid.com',\n",
              " 'Переводчики: lifeful, MuigeTuired, _Folko_, Otesla, MishanF, plumbumbullet, Dyadya_Jenya',\n",
              " 'Господа, полагаю, я нашел',\n",
              " 'увлекательный способ, призванный ',\n",
              " 'заинтересовать молодое поколение наукой.',\n",
              " 'Физическое стенд-ап шоу.',\n",
              " '-Так, назовите мне любое число.',\n",
              " 'Иррациональную константу.',\n",
              " 'И смешную букву греческого алфавита.',\n",
              " 'Я просил смешную.',\n",
              " 'Эпсилон?',\n",
              " 'Отлично.',\n",
              " 'И электрический заряд.',\n",
              " 'Положительный.',\n",
              " 'Идеально.',\n",
              " 'А теперь слушайте.',\n",
              " 'Профессор Джонс объявил на симпозиуме, ',\n",
              " 'что у него есть новый метод.',\n",
              " 'вычисления массы мюона.',\n",
              " '\"Пять умножить на предел Е к эпсилон как..\"',\n",
              " 'Так. Нет, не то.',\n",
              " 'Начну сначала.',\n",
              " '\"Профессор..\"',\n",
              " 'Я не видел, чтобы он так смеялся',\n",
              " 'с того дня, как Леонард допустил',\n",
              " 'ту ошибку при умножении.',\n",
              " 'О, о боже ж ты мой,',\n",
              " ' та ошибка при умножении!',\n",
              " 'Он думал, что',\n",
              " 'он перенес единицу.',\n",
              " 'Но он не перенес.',\n",
              " 'Это не смешно.',\n",
              " 'Ту ошибку опубликовали.',\n",
              " 'Перестань! Я же сейчас описаюсь!',\n",
              " 'Эй парни, сюда идет президент Сиберт.',\n",
              " 'Хотел бы я знать что ему нужно.',\n",
              " 'Выглядит не слишком ',\n",
              " 'счастливым, полагаю,',\n",
              " 'грядет разговор с Шелдоном.',\n",
              " 'Доктор Купер?',\n",
              " 'Говорил же.',\n",
              " 'О, Президент Сиберт,',\n",
              " 'Полагаю, что вы хотите ответить на одно из моих предложений,',\n",
              " 'Которые я оставил в вашем офисе.',\n",
              " 'Нет, и прекратите ставить повсюду эти дурацкие ящики для сбора предложений.',\n",
              " 'Вам не понравились мои предложения?',\n",
              " 'Вам не понравилось, что я передал вам их во время мочеиспускания',\n",
              " 'в уборной.',\n",
              " 'Если бы я не знал вас,',\n",
              " 'то сказал бы, что вы один из тех',\n",
              " 'упрямцев,',\n",
              " 'которые не прислушиваются к чужому мнению.',\n",
              " 'Доктор купер, на кафедре физики  мне сказали,',\n",
              " 'что вы отказываетесь брать отпуск.',\n",
              " 'Мне не нужен отпуск.',\n",
              " 'Вы обязаны его взять.',\n",
              " 'И я хотел бы вам сообщить,',\n",
              " 'что наиболее частое предложение',\n",
              " 'в коробке для предложений, ',\n",
              " 'установленной вами без согласования со мной,',\n",
              " 'это \"пусть доктор Купер уйдет уже в отпуск.\"',\n",
              " 'Итак, решено.',\n",
              " 'Увидимся в понедельник,',\n",
              " 'со всеми, кроме вас.',\n",
              " 'Но если я не пойду на работу,',\n",
              " 'чем, предполагается, я буду заниматься?',\n",
              " 'Читать, отдыхать, путешествовать.',\n",
              " 'Я слышал, что Афганистан ',\n",
              " 'бесподобен в это время года.',\n",
              " 'Сарказм?',\n",
              " 'Нет. Тебе стоит поехать.',\n",
              " '\"Теория Большого Взрыва\"',\n",
              " '\"Проблема отпуска\"',\n",
              " 'оригинальные субтитры: addic7ed.com',\n",
              " 'перевод: notabenoid.com',\n",
              " 'Боже милосердный!',\n",
              " 'Прекрати эти визги.',\n",
              " 'Что, чёрт возьми, ты делаешь?',\n",
              " 'Умираю от ушного кровотечения.',\n",
              " 'Зачем ты там прячешься?',\n",
              " 'Чтобы тайком пробраться на работу.',\n",
              " 'Если охранник на входе спросит,',\n",
              " 'что у тебя под одеялом,',\n",
              " 'скажешь, что это сетки для ловли раков.',\n",
              " '- Сетки для ловли раков?',\n",
              " 'Именно так Велма и Скуби',\n",
              " 'тайно провели Шэгги на старый маяк.',\n",
              " 'Что ты собираешься делать,',\n",
              " 'когда попадешь в университет?',\n",
              " 'Тебя все равно опознают.',\n",
              " 'Полагаешь, Леонард?',\n",
              " 'Ладно. Залезай под одеяло,',\n",
              " 'и я тебя провезу.',\n",
              " 'И больше не пой.',\n",
              " 'Ладно.',\n",
              " 'У меня в телефоне GPS.',\n",
              " 'Я знаю, что ты развернулся.',\n",
              " 'Я так рада, что ты отговорила Говарда',\n",
              " 'писать свадебные приглашения',\n",
              " ' на клингонском.',\n",
              " 'Переверни.',\n",
              " 'Надеюсь, моя родня подумает,',\n",
              " 'что это иврит.',\n",
              " 'Это и впрямь происходит.',\n",
              " 'Я буду главной подружкой.',\n",
              " 'Я в красивом платье буду идти по проходу между рядами,',\n",
              " 'и наконец наступит мой особенный день.',\n",
              " 'Ты хочешь сказать - мой особенный день?',\n",
              " 'Кое-кому понадобится очень большая фата.',\n",
              " 'Если я вообще когда-нибудь выйду замуж.',\n",
              " 'Почему нет?',\n",
              " 'Отец...',\n",
              " 'Из-за того, что я зарабатываю',\n",
              " 'много больше Говардушки,',\n",
              " 'он заставляет меня подписать',\n",
              " 'брачный контракт.',\n",
              " 'Да уж. Говардушка взбесится.',\n",
              " 'Давление родителей изматывает.',\n",
              " 'Помню ту ссору с матерью  ',\n",
              " 'из-за бритья моих лодыжек.',\n",
              " 'В прошлом году я наконец сдалась',\n",
              " 'и разрешила ей это сделать.',\n",
              " 'Я просто не знаю, как ему это сказать.',\n",
              " 'Знаешь, я верю, что лучше',\n",
              " 'всего плохие новости',\n",
              " 'сообщать парню, когда вы',\n",
              " 'с ним в постели.',\n",
              " 'Вот как я сказала своему ',\n",
              " 'университетскому бойфренду,',\n",
              " 'что спала с его братом.',\n",
              " 'И точно так же я ',\n",
              " 'то же самое сказала его брату.',\n",
              " 'Ну не знаю, не хочу манипулировать',\n",
              " 'им с помощью секса.',\n",
              " 'Милая, секс для этого и создан.',\n",
              " 'Знаешь, взаимосвязь',\n",
              " 'между замужеством и ',\n",
              " 'деньгами - не новость.',\n",
              " 'Изначально, слово \"брак\" произошло',\n",
              " 'от \"оброка\",',\n",
              " 'который жених выплачивал отцу невесты.',\n",
              " 'Например,',\n",
              " 'ты обворожительна,',\n",
              " 'умна и хорошо зарабатываешь.',\n",
              " 'По самым первым прикидкам ',\n",
              " 'за тебя можно выручить',\n",
              " 'минимум двух быков и гуся.',\n",
              " 'А за тебя - единорога.',\n",
              " 'Шелдон, у тебя есть миллион способов провести отличный отпуск.',\n",
              " 'Как насчёт Гавайев?',\n",
              " 'Гавайи — это бывший лепрозорий на вершине действующего вулкана,',\n",
              " 'где была снята разочаровывающая концовка ЛОСТа.',\n",
              " 'Гавайи? Спасибо, не надо.',\n",
              " 'А может Флорида?',\n",
              " 'У них там есть мыс Канаверал,',\n",
              " 'Дисней, моя тётя Ида',\n",
              " 'и самая большая в мире',\n",
              " 'коллекция диабетических конфет.',\n",
              " 'К тому же, если ты вспотеешь,',\n",
              " 'её пластиковые стулья будут напоминать горки в аквапарке.',\n",
              " 'Моя семья путешествовала ',\n",
              " 'во Флориду, когда я был ребёнком.',\n",
              " 'Чайка стащила у меня хот-дог',\n",
              " 'на пляже.',\n",
              " 'Это было посланием.',\n",
              " 'Знаете, если б у меня была неделька отдыха,',\n",
              " 'я б опять съездил бы',\n",
              " 'на\" Курорт двух пальм и Спа\" ',\n",
              " 'в пустыне.',\n",
              " 'Я скажу тебе, час на масажном столе с Тревором,',\n",
              " 'и ты будешь чувствовать себя как будто у тебя не костей.',\n",
              " 'Не думаю, что когда-либо позволю ',\n",
              " 'парню сделать мне массаж.',\n",
              " 'Правда? А что я тогда',\n",
              " 'с твоей шеей делал,',\n",
              " 'пока ты играл в Х-box?',\n",
              " 'Я как будто живу под гнетом',\n",
              " 'диктатуры.',\n",
              " '\"Вы должны взять отпуск,',\n",
              " 'вы обязаны веселиться,',\n",
              " 'вам следует наслаждаться жизнью.\"',\n",
              " 'Не думаю, что ты разбираешься',\n",
              " 'в диктатурах.',\n",
              " 'Шелдон, все ходят в отпуск.',\n",
              " 'Однажды Ричарда Фейнмана',\n",
              " 'пытались заставить взять отпуск,',\n",
              " 'но он предпочел вместо этого',\n",
              " 'развивать интеллект',\n",
              " 'и учиться чему-то новому.',\n",
              " 'Он отправился работать ',\n",
              " 'в биолабораторию своего друга.',\n",
              " 'Ричард Фейнман был знаменитым',\n",
              " 'американским физиком,',\n",
              " 'участником проекта \"Манхэттен\".',\n",
              " 'Все в мире науки знают, кто такой Ричард Фейнман.',\n",
              " 'Вот и ты теперь тоже.',\n",
              " 'О, у меня потрясающая идея!',\n",
              " 'Эми - биолог, пойду',\n",
              " 'поработаю в ее лаборатории.',\n",
              " 'А разве это не идея Фейнмана?',\n",
              " 'Еще десять секунд назад ты о нем даже не слышал.',\n",
              " 'А теперь ты эксперт.',\n",
              " 'Привет.',\n",
              " '- Привет.',\n",
              " '- Это для стирки?',\n",
              " 'У тебя же тут, сколько, вещей шесть?',\n",
              " 'Ага, у меня кончились четвертаки,',\n",
              " 'и я весь день распихивала вещи',\n",
              " 'по стиралкам других жильцов.',\n",
              " 'Эй, если я скажу тебе кое-что',\n",
              " 'обещаешь, что никому не скажешь?',\n",
              " 'Какая разница, что я отвечу, ты расскажешь мне все равно.',\n",
              " 'Что? Это не правда.',\n",
              " 'Бернадет хочет ',\n",
              " 'брачный договор.',\n",
              " 'Ого. Это жестко.',\n",
              " 'Значит, ты говоришь, что если я стану',\n",
              " 'известной кинозвездой',\n",
              " 'и мы поженимся, ты не ',\n",
              " 'подпишешь брачный договор?',\n",
              " 'Конечно нет.',\n",
              " 'Если я застряну дома с детьми',\n",
              " 'пока ты на съемках',\n",
              " 'изменяешь мне с Районом Гослингом...',\n",
              " 'ты дорого заплатишь за это.',\n",
              " 'Значит, ты думаешь ',\n",
              " 'о том, что мы поженимся?',\n",
              " 'Я думаю о многих вещах.',\n",
              " 'Думаю о том, как мы поженимся,',\n",
              " 'Как разведемся.',\n",
              " 'Иногда я думаю о том,',\n",
              " 'как я не оставила записку на том Мерседесе,',\n",
              " 'который поцарапала на парковке в прошлом месяце,',\n",
              " 'но затем выпиваю бокальчик вина и всё проходит.',\n",
              " 'Шути сколько хочешь, ',\n",
              " 'но ты думаешь об этом.',\n",
              " 'Ну, я скажу тебе одно,',\n",
              " 'если я когда-нибудь выйду замуж, никаких приглашений на клингонском.',\n",
              " 'Удачи найти такого мужчину.',\n",
              " 'Боже ж мой!',\n",
              " 'Этот отпуск начался просто',\n",
              " 'удивительно.',\n",
              " 'Запах формальдегида..',\n",
              " 'шум центрифуги,',\n",
              " 'отдаленная болтовня',\n",
              " 'лабораторных животных',\n",
              " 'отправленных на вивисекцию.',\n",
              " 'Мм, я уже чувствую как ',\n",
              " 'мои заботы просто тают.',\n",
              " 'Я в восторге от того, что буду работать с моим парнем.',\n",
              " 'Это так романтично.',\n",
              " 'Прямо убивает настроение.',\n",
              " 'Да ладно, Шелдон.',\n",
              " 'Мы можем быть, как Мария Кюри ',\n",
              " 'с мужем Пьером,',\n",
              " 'которые всю свою жизнь ',\n",
              " 'работали бок о бок,',\n",
              " 'омывались жаром своей любви и радия,',\n",
              " 'что в итоге и убило её.',\n",
              " 'К черту \"Красавицу и чудовище\",',\n",
              " 'Диснею стоило рассказать',\n",
              " 'эту историю любви.',\n",
              " 'Ладно, и с чего мы начнем?',\n",
              " 'Может, соеденим кое-какие гены,',\n",
              " 'клонируем овцу,',\n",
              " 'или вырастим человеческое ухо',\n",
              " 'на спине мыши?',\n",
              " 'Ха-ха, я уродец!',\n",
              " 'Я буду делать',\n",
              " 'гистологию ствола головного мозга,',\n",
              " 'пока ты заставишь себя',\n",
              " 'взять в руки губку',\n",
              " 'и помоешь эти стаканы.',\n",
              " 'Помоешь эти ста...',\n",
              " 'Я понял, небольшая издевка ',\n",
              " 'над новым напарником.',\n",
              " 'И что же будет потом,',\n",
              " 'крем для обуви на микроскопе',\n",
              " 'Или вирус коровьего бешенства в моём мендвиче?',\n",
              " 'Нет, просто мне нужно, чтобы эти стаканы были чистыми.',\n",
              " 'Давай-ка, метнулся кабанчиком.',\n",
              " 'Что? Извини меня, но',\n",
              " 'в твоей лаборатории ',\n",
              " 'доктор Шелдон Купер.',\n",
              " 'А ты заставляешь ',\n",
              " 'его мыть посуду?',\n",
              " 'Это как-будто просить ',\n",
              " 'Невероятного Халка',\n",
              " 'отрыть банку огурцов.',\n",
              " 'Шелдон, ты никогда до этого ',\n",
              " 'не работал в лаборатории.',\n",
              " 'У тебя нет опыта ',\n",
              " 'в области биологии.',\n",
              " 'У меня достаточно ',\n",
              " 'опыта в биологии.',\n",
              " 'Я купил Тамагочи в 1998.',\n",
              " 'оно все еще живое.',\n",
              " 'Давай сделаем Это.',\n",
              " '- Где Говард?',\n",
              " '- Никаких \"Привет, Радж\"?',\n",
              " 'или \"Как ты, Радж\"?',\n",
              " 'Сразу \"Где другой белый парень\"?',\n",
              " 'Извини.',\n",
              " 'Итак, слушай,',\n",
              " 'Я слышал кое-что о нем.',\n",
              " 'Можешь оставить это между нами?',\n",
              " 'О, сплетня.',\n",
              " 'Когда я приехал сюда,',\n",
              " 'я думал вы Американцы',\n",
              " 'сплетничаете около кулера.',\n",
              " 'Так что я ошивался там около месяца,',\n",
              " 'но единственная сплетня, которую я услышал была о каком-то придурке,',\n",
              " 'который трётся около кулера.',\n",
              " 'Бернадет хочет ',\n",
              " 'брачный договор.',\n",
              " 'О, это досадно - ',\n",
              " 'он будет опустошен.',\n",
              " 'Я не знаю, что делать в таких ситуациях.',\n",
              " 'Мне нужно позволить ему побыть одному?',\n",
              " 'Хм. Я дам тебе тот же совет',\n",
              " 'который кричал на телевизор, когда ',\n",
              " 'Холостяк раздавал розы.',\n",
              " 'Следуй зову сердца.',\n",
              " 'Зацените.',\n",
              " 'Только посмотрите, какой огромный',\n",
              " 'рисовый пирог.',\n",
              " 'За ту же цену.',\n",
              " 'Слушай, Говард, мне нужно кое-что тебе сказать.',\n",
              " 'Я знаю, этого нету',\n",
              " 'в моей свадебной диете.',\n",
              " 'Мне все равно.',\n",
              " 'Эм, с-слушай, я',\n",
              " 'слышал, что Бернадет думает о том, чтобы предложить тебе брачный контракт.',\n",
              " 'Брачный контракт?',\n",
              " 'Что ты будешь делать?',\n",
              " 'Я... не знаю.',\n",
              " 'Сердце подскажет.',\n",
              " 'Знаешь что... ',\n",
              " 'ну и пофиг.',\n",
              " 'Она зарабатывает больше меня.',\n",
              " 'Она хочет защитить свои финансовые интересы.',\n",
              " 'Это вполне логично.',\n",
              " 'Хорошо. Это здравый подход.',\n",
              " 'Да, на самом деле,',\n",
              " 'это выгодно нам обоим.',\n",
              " 'Мне тоже есть что сохранить.',\n",
              " 'Что например?',\n",
              " 'Ну, например, редкие комиксы.',\n",
              " 'Мотороллер почти выкуплен.',\n",
              " 'И у нас с мамой два местечка на кладбище у горы Синай',\n",
              " 'Прямо рядом с парнем, который играл мистера Ропера в сериале «Трое — это компания».',\n",
              " 'Мистер Ропер мертв?!',\n",
              " 'Нельзя говорить о таких вещах вскользь.',\n",
              " 'Вот, держи.',\n",
              " 'Теперь это единственная лаборатория,',\n",
              " 'в которой мензурки моет',\n",
              " 'обладатель двух докторских',\n",
              " 'и судебного запрета, подписанного Карлом Саганом.',\n",
              " 'Мыльные разводы. Мой снова.',\n",
              " 'Т..ты придираешься!',\n",
              " 'Они идеально чистые.',\n",
              " 'Шелдон, в этой пробирке',\n",
              " 'была спинно-мозговая жидкость',\n",
              " 'умершего от сифилиса слона.',\n",
              " 'Если, как ты говоришь, она',\n",
              " 'девственно чиста,',\n",
              " 'попей из нее.',\n",
              " 'Биологи такие зануды.',\n",
              " 'Хорошо, допустим это задание',\n",
              " 'будет немного больше по твоей части',\n",
              " 'Мне нужно чтобы ты сосчитал ',\n",
              " 'споры бактерий',\n",
              " 'в этих чашках петри',\n",
              " 'С моющим средством было что-то не так',\n",
              " 'Слишком пузыристое',\n",
              " 'Я уверен, что так и было',\n",
              " 'Я намереваюсь написать',\n",
              " 'в компанию, выпускающую моющие средства,',\n",
              " 'серьезное письмо',\n",
              " 'Да, молодец!',\n",
              " 'Теперь начинай считать',\n",
              " 'Ты знаешь, чего не хватает этому месту?',\n",
              " 'Ящика для предложений.',\n",
              " 'Как успехи?',\n",
              " 'Как мои успехи в подсчетах?',\n",
              " 'Когда я был в детском саду,',\n",
              " 'Я зачитывал наизусть число \"ПИ\"',\n",
              " 'до тысячной цифры после запятой',\n",
              " 'для школьного конкурса талантов',\n",
              " 'Думаю, я справился.',\n",
              " 'Отлично.',\n",
              " 'Вот блин!',\n",
              " 'Один...',\n",
              " 'Это нелепо!',\n",
              " 'Думаю, что ты даешь мне ',\n",
              " 'эти задания,',\n",
              " 'потому что боишься, что дав мне',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI6xdYA7GC6w"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=200, analyzer='char')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieEjzfQyFHEj",
        "outputId": "c3739260-6bc4-499c-99fa-4bc057798c32"
      },
      "source": [
        "vectorizer.fit(text[:len(text)//2])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=200,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY7aA12RGOZj"
      },
      "source": [
        "x = vectorizer.transform(['как дела?'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLH6OvIcGp0X",
        "outputId": "95bc5542-997a-47e3-a017-eb77718d1d32"
      },
      "source": [
        "len(x.toarray()[0])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vukzq4SDHnty"
      },
      "source": [
        "y = vectorizer.transform(text[:3])"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qwtppHiHu6w",
        "outputId": "57fcaa2e-8a64-4dcd-fb30-73500fe64881"
      },
      "source": [
        "len(y.toarray()[0])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaT-kHbxIVFj"
      },
      "source": [
        "from scipy.spatial import distance"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1togNgd6Idzs",
        "outputId": "168edcbe-614d-43e0-a157-5f242752519e"
      },
      "source": [
        "distance.cosine(x.toarray()[0], y.toarray()[2])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6189624225348822"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfzSslATkAbi",
        "outputId": "479719b8-c52c-4079-a37a-8bb23a737c71"
      },
      "source": [
        "!zip -r 'training_checkpoints.zip' 'training_checkpoints'"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: training_checkpoints/ (stored 0%)\n",
            "updating: training_checkpoints/ckpt_18.index (deflated 72%)\n",
            "updating: training_checkpoints/ckpt_12.index (deflated 72%)\n",
            "updating: training_checkpoints/ckpt_2.data-00000-of-00001\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2pXicg1I-VM"
      },
      "source": [
        "\n",
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 200\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    \n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6,]\n",
        "    for temp in temperature:\n",
        "        input_eval = [char2idx[s] for s in start_string]\n",
        "        input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "        # Here batch size == 1\n",
        "        model.reset_states()\n",
        "        for i in range(num_generate):\n",
        "            predictions = model(input_eval)\n",
        "            predictions = tf.squeeze(predictions, 0)\n",
        "            # using a categorical distribution to predict the character returned by the model\n",
        "            predictions = predictions / temp\n",
        "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "            # Pass the predicted character as the next input to the model\n",
        "            # along with the previous hidden state\n",
        "            input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "            text_generated.append(idx2char[predicted_id])\n",
        "    \n",
        "    text_generated = ''.join(text_generated).split('\\n')\n",
        "    x = vectorizer.transform([start_string]).toarray()\n",
        "    y = vectorizer.transform(text_generated).toarray()\n",
        "    index = 0\n",
        "    min_val = distance.cosine(x[0], y[0])\n",
        "    for i in range(1, len(y)):\n",
        "        val = distance.cosine(x[0], y[i])\n",
        "        if val < min_val:\n",
        "            min_val = val\n",
        "            index = i\n",
        "    \n",
        "    return text_generated[index]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcGM0JZLmZKQ",
        "outputId": "2a6c52a3-43a1-4853-dff4-46299d3031e6"
      },
      "source": [
        "model.save(\"my_model\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Ofjj9zwNSw",
        "outputId": "b3807dab-5d15-49c3-8af7-6e0a26935160"
      },
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"my_model\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-htkNs2-wqaN"
      },
      "source": [
        "model = reconstructed_model.compile()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhNXoAcUwuUV",
        "outputId": "103611ca-32f9-4d34-9c77-515918d2e1ff"
      },
      "source": [
        "text_ = generate_text(reconstructed_model, start_string=u\"кто вы? \")\n",
        "print(text_)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "кто вы? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC0sItKHw2S-",
        "outputId": "0da00d0b-42a2-416a-a7b8-d9bf97f12bab"
      },
      "source": [
        "!zip -r 'my_model.zip' 'my_model'"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: my_model/ (stored 0%)\n",
            "  adding: my_model/variables/ (stored 0%)\n",
            "  adding: my_model/variables/variables.index (deflated 64%)\n",
            "  adding: my_model/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: my_model/keras_metadata.pb (deflated 93%)\n",
            "  adding: my_model/saved_model.pb (deflated 90%)\n",
            "  adding: my_model/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6qGtEsOh1jE",
        "outputId": "c21660c1-8be5-41e5-8cd0-0c5c27796549"
      },
      "source": [
        "!unzip /content/my_model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/my_model.zip\n",
            "   creating: my_model/\n",
            "   creating: my_model/variables/\n",
            "  inflating: my_model/variables/variables.data-00000-of-00001  \n",
            "  inflating: my_model/variables/variables.index  \n",
            "  inflating: my_model/saved_model.pb  \n",
            "  inflating: my_model/keras_metadata.pb  \n",
            "   creating: my_model/assets/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2V6SRcLFaY",
        "outputId": "6ab2f8f2-1cc6-42a6-d828-dc74722706e5"
      },
      "source": [
        "!unzip static.zip"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  static.zip\n",
            "   creating: static/\n",
            "  inflating: static/.DS_Store        \n",
            "  inflating: __MACOSX/static/._.DS_Store  \n",
            "  inflating: static/welcome.webp     \n",
            "  inflating: __MACOSX/static/._welcome.webp  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVvdIGdfw_v7",
        "outputId": "d191525a-aca7-425a-95dd-a56f733463be"
      },
      "source": [
        "print(text_)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "кто вы? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYUeAw9qSXgp",
        "outputId": "05932b55-cec5-4aab-deb4-58ad0687cfef"
      },
      "source": [
        "text_ = generate_text(model, start_string=u\"Привет \")\n",
        "print(text_)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Припривет.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk07WENpSgb0",
        "outputId": "c17156e8-4594-413c-eb79-3d1725dea0a7"
      },
      "source": [
        "!pip install telebot"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting telebot\n",
            "  Downloading telebot-0.0.4-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from telebot) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->telebot) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->telebot) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->telebot) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->telebot) (2021.5.30)\n",
            "Installing collected packages: telebot\n",
            "Successfully installed telebot-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcApsYasTEHp",
        "outputId": "a43932c9-f65b-4467-e4d9-357837b5a404"
      },
      "source": [
        "!pip install pyTelegramBotAPI"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pyTelegramBotAPI-4.1.1.tar.gz (102 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pyTelegramBotAPI) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.1.1-py3-none-any.whl size=80779 sha256=f595a406413e754e07ca9e9bce00d833fc370a344f1c19389eca42dab8d972e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/9d/f5/f589ebef11a6541a4e5a1793a380db577bab5583eac6b45514\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9yKPFlSTcK8",
        "outputId": "d5031719-3295-4ce7-dd4e-875a6f27eee0"
      },
      "source": [
        "text_ = generate_text(model, start_string=u\"кто вы? \")\n",
        "print(text_)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вы знаете, кто это?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP-qvW27T75L",
        "outputId": "327443ab-8f44-4d38-9d7a-c2bfaa97f449"
      },
      "source": [
        "import random\n",
        "text_.split('\\n')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Какой ещё друг?',\n",
              " 'Просто поговорим.',\n",
              " 'Поговори с Ригсби.',\n",
              " 'Ригсби, проверь камеры наблюдения.',\n",
              " 'Да, босс.',\n",
              " 'Нет, нет. Дух звонили.',\n",
              " 'Слушай, я знаю, что вы сделали.',\n",
              " 'Спасибо.',\n",
              " 'Вы можете присоединиться к нам.',\n",
              " 'Да, мы поняли, когда он начал разговаривать.',\n",
              " '- Мы должны держаться в стороне.',\n",
              " '- Почему вы так долго?',\n",
              " '— Да, я в порядке.',\n",
              " 'Вы сказали, что вы думаете о моей матери.',\n",
              " '- Не видели Джереми?',\n",
              " 'Он был здесь вчера вечером. Это было нечто не угодно.',\n",
              " 'И вы пошли после убийства.',\n",
              " 'Вы забрали его после того, как вы скажете ']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd1C8s-SnY2i"
      },
      "source": [
        "vocab = ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\xa0', '«', '°', '»', '×', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '\\u200b', '–', '—', '’', '“', '”', '…', '€', '№', '♪']\n",
        "char2idx = {'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '<': 29, '=': 30, '>': 31, '?': 32, '@': 33, 'A': 34, 'B': 35, 'C': 36, 'D': 37, 'E': 38, 'F': 39, 'G': 40, 'H': 41, 'I': 42, 'J': 43, 'K': 44, 'L': 45, 'M': 46, 'N': 47, 'O': 48, 'P': 49, 'Q': 50, 'R': 51, 'S': 52, 'T': 53, 'U': 54, 'V': 55, 'W': 56, 'X': 57, 'Y': 58, 'Z': 59, '[': 60, '\\\\': 61, ']': 62, '^': 63, '_': 64, '`': 65, 'a': 66, 'b': 67, 'c': 68, 'd': 69, 'e': 70, 'f': 71, 'g': 72, 'h': 73, 'i': 74, 'j': 75, 'k': 76, 'l': 77, 'm': 78, 'n': 79, 'o': 80, 'p': 81, 'q': 82, 'r': 83, 's': 84, 't': 85, 'u': 86, 'v': 87, 'w': 88, 'x': 89, 'y': 90, 'z': 91, '~': 92, '\\xa0': 93, '«': 94, '°': 95, '»': 96, '×': 97, 'Ё': 98, 'А': 99, 'Б': 100, 'В': 101, 'Г': 102, 'Д': 103, 'Е': 104, 'Ж': 105, 'З': 106, 'И': 107, 'Й': 108, 'К': 109, 'Л': 110, 'М': 111, 'Н': 112, 'О': 113, 'П': 114, 'Р': 115, 'С': 116, 'Т': 117, 'У': 118, 'Ф': 119, 'Х': 120, 'Ц': 121, 'Ч': 122, 'Ш': 123, 'Щ': 124, 'Ы': 125, 'Ь': 126, 'Э': 127, 'Ю': 128, 'Я': 129, 'а': 130, 'б': 131, 'в': 132, 'г': 133, 'д': 134, 'е': 135, 'ж': 136, 'з': 137, 'и': 138, 'й': 139, 'к': 140, 'л': 141, 'м': 142, 'н': 143, 'о': 144, 'п': 145, 'р': 146, 'с': 147, 'т': 148, 'у': 149, 'ф': 150, 'х': 151, 'ц': 152, 'ч': 153, 'ш': 154, 'щ': 155, 'ъ': 156, 'ы': 157, 'ь': 158, 'э': 159, 'ю': 160, 'я': 161, 'ё': 162, '\\u200b': 163, '–': 164, '—': 165, '’': 166, '“': 167, '”': 168, '…': 169, '€': 170, '№': 171, '♪': 172}\n",
        "idx2char = np.array(['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0',\n",
        " '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B',\n",
        " 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
        " 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f',\n",
        " 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        " 'y', 'z', '~', '\\xa0', '«', '°', '»', '×', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З',\n",
        " 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ',\n",
        " 'Ы', 'Ь', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м',\n",
        " 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь' ,'э', 'ю',\n",
        " 'я', 'ё', '\\u200b', '–', '—', '’', '“', '”', '…', '€', '№', '♪'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JqilTw-uVLJN",
        "outputId": "e11974fb-674c-4e15-bb03-5bedf2d8d694"
      },
      "source": [
        "random.choice(text_.split('\\n'))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'— Да, я в порядке.'"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "SzWFzlEtXJyo",
        "outputId": "021dfdb2-8946-4d50-c678-20c4b555e8b5"
      },
      "source": [
        "import confing\n",
        "import telebot\n",
        "from telebot import types\n",
        "bot = telebot.TeleBot(confing.TOKEN)\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def welcome(message):\n",
        "    sti = open('static/welcome.webp', 'rb')\n",
        "    bot.send_sticker(message.chat.id, sti)\n",
        "\n",
        "    # keyboard\n",
        "    # markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
        "    # item1 = types.KeyboardButton(\"🎲 Рандомное число\")\n",
        "    # item2 = types.KeyboardButton(\"😊 Как дела?\")\n",
        "    #\n",
        "    # markup.add(item1, item2)\n",
        "\n",
        "    bot.send_message(message.chat.id,\n",
        "                     \"Добро пожаловать, {0.first_name}!\\nЯ - <b>{1.first_name}</b>,\"\n",
        "                     \" бот созданный чтобы быть переводчиком китайский-русский.\".format(\n",
        "                         message.from_user, bot.get_me()),\n",
        "                     parse_mode='html',) # reply_markup=markup)\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def lalala(message):\n",
        "    if message.chat.type == 'private':\n",
        "        if message.text == '🎲 Рандомное число':\n",
        "            bot.send_message(message.chat.id, str(random.randint(0, 100)))\n",
        "        elif message.text == '😊 Как дела?':\n",
        "\n",
        "            markup = types.InlineKeyboardMarkup(row_width=2)\n",
        "            item1 = types.InlineKeyboardButton(\"Хорошо\", callback_data='good')\n",
        "            item2 = types.InlineKeyboardButton(\"Не очень\", callback_data='bad')\n",
        "\n",
        "            markup.add(item1, item2)\n",
        "\n",
        "            bot.send_message(message.chat.id, 'Отлично, сам как?', reply_markup=markup)\n",
        "        elif message.text:\n",
        "            # url = get_url(message.text)\n",
        "            # soup = get_soup(url)\n",
        "            # words = translate(soup)\n",
        "            # for i in words:\n",
        "            #     bot.send_message(message.chat.id, i)\n",
        "            bot.send_message(message.chat.id, generate_text(model, start_string=message.text).split('\\n'))\n",
        "\n",
        "\n",
        "        else:\n",
        "            bot.send_message(message.chat.id, 'Я не знаю что ответить 😢')\n",
        "\n",
        "\n",
        "@bot.callback_query_handler(func=lambda call: True)\n",
        "def callback_inline(call):\n",
        "    try:\n",
        "        if call.message:\n",
        "            if call.data == 'good':\n",
        "                bot.send_message(call.message.chat.id, 'Вот и отличненько 😊')\n",
        "            elif call.data == 'bad':\n",
        "                bot.send_message(call.message.chat.id, 'Бывает 😢')\n",
        "\n",
        "            # remove inline buttons\n",
        "            bot.edit_message_text(chat_id=call.message.chat.id, message_id=call.message.message_id, text=\"😊 Как дела?\",\n",
        "                                  reply_markup=None)\n",
        "\n",
        "            # show alert\n",
        "            bot.answer_callback_query(callback_query_id=call.id, show_alert=False,\n",
        "                                      text=\"ЭТО ТЕСТОВОЕ УВЕДОМЛЕНИЕ!!11\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(repr(e))\n",
        "\n",
        "\n",
        "# RUN\n",
        "bot.polling(none_stop=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f295397e3122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# RUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnone_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36mpolling\u001b[0;34m(self, non_stop, skip_pending, interval, timeout, long_polling_timeout, allowed_updates, none_stop)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__threaded_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_polling_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__non_threaded_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_polling_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36m__threaded_polling\u001b[0;34m(self, non_stop, interval, timeout, long_polling_timeout, allowed_updates)\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/telebot/__init__.py\u001b[0m in \u001b[0;36m__threaded_polling\u001b[0;34m(self, non_stop, interval, timeout, long_polling_timeout, allowed_updates)\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mor_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for polling thread finish, polling thread error or thread pool error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0mpolling_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m                 \u001b[0merror_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mapihelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApiException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/telebot/util.py\u001b[0m in \u001b[0;36mraise_exceptions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/telebot/util.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceived_task_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Task complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-f295397e3122>\u001b[0m in \u001b[0;36mwelcome\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwelcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'static/welcome.webp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_sticker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'static/welcome.webp'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJUCVMLydVxv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}