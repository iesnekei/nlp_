{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdM7c3hyXZWb"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9TAn34HYL_F"
      },
      "source": [
        "Осуществим предобработку данных с Твиттера, чтобы отчищенный данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания.\n",
        "Для работы объединим train_df и test_df."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9M3fL5dX_tt"
      },
      "source": [
        "train_df = pd.read_csv('train_tweets.csv')\n",
        "test_df = pd.read_csv('test_tweets.csv')\n",
        "combine_df = train_df.append(test_df, ignore_index = True, sort = False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7MFbuIvYUjg"
      },
      "source": [
        "1) Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
        " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
        " - для для замены @user на пробел, необходимо использовать re.sub()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOKr4V6VYOgO"
      },
      "source": [
        "import re"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLD-n7-DYXzu"
      },
      "source": [
        "# Delete @user by re\n",
        "def del_user(x):\n",
        "    to_del = re.findall(\"@[\\w]*\", x)\n",
        "    for mail in to_del:\n",
        "        x = re.sub(mail, '', x)\n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "cWjwIsjIY3gV",
        "outputId": "b50fcfc2-ff48-4a2f-f48e-34d55b495ddf"
      },
      "source": [
        "test_1 = combine_df.tweet[0]\n",
        "test_1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ycCdF7wmZJhl",
        "outputId": "46ac13aa-0b90-48b1-d5de-24eb3f1a62ef"
      },
      "source": [
        "del_user(test_1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ZK9rYF7eZVmF",
        "outputId": "ffc1f47a-85de-429d-9c9d-03e29acbdaac"
      },
      "source": [
        "test_2 = combine_df.tweet[1]\n",
        "test_2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "6KeRT7mYafzr",
        "outputId": "3cd574d1-b880-45b4-c7af-66c07a4f6275"
      },
      "source": [
        "del_user(test_2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd8d-Tfwaj7q"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(del_user)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzw9C5VDawfx",
        "outputId": "9db64c24-506b-4f81-a4ab-1acc2bd591ed"
      },
      "source": [
        "combine_df.tweet[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      when a father is dysfunctional and is so sel...\n",
              "1      thanks for #lyft credit i can't use cause th...\n",
              "2                                  bihday your majesty\n",
              "3    #model   i love u take with u all the time in ...\n",
              "4               factsguide: society now    #motivation\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDok5Psla7bP"
      },
      "source": [
        "2) Изменим регистр твитов на нижний с помощью .lower()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoduRCM4a1fD"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: x.lower())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg4xlJ9SbHfs",
        "outputId": "eb341b03-c2e7-4fb3-c2ce-5539096526b8"
      },
      "source": [
        "combine_df.tweet[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      when a father is dysfunctional and is so sel...\n",
              "1      thanks for #lyft credit i can't use cause th...\n",
              "2                                  bihday your majesty\n",
              "3    #model   i love u take with u all the time in ...\n",
              "4               factsguide: society now    #motivation\n",
              "Name: tweet, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2KPARznbhQH"
      },
      "source": [
        "3) Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPcCChXbKZU"
      },
      "source": [
        "def change_word(x:str, to_change:dict):\n",
        "    # Change apostrophe in text\n",
        "    origin_list = x.split()\n",
        "    new_list = []\n",
        "    for word in origin_list:\n",
        "        if word in to_change:\n",
        "            new_list.append(to_change[word])\n",
        "        else:\n",
        "            new_list.append(word)\n",
        "    return ' '.join(new_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQavgIpdoY6"
      },
      "source": [
        "apostrophe_dict = {\n",
        "\"ain't\": \"am not / are not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is\",\n",
        "\"i'd\": \"I had / I would\",\n",
        "\"i'd've\": \"I would have\",\n",
        "\"i'll\": \"I shall / I will\",\n",
        "\"i'll've\": \"I shall have / I will have\",\n",
        "\"i'm\": \"I am\",\n",
        "\"i've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "SwPRUkK3dZKa",
        "outputId": "14e75822-7799-4bc9-852d-729ca7dac09d"
      },
      "source": [
        "test_1 = combine_df.tweet[1]\n",
        "test_1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "fxVBIQGPdePK",
        "outputId": "4edadfa3-e16b-498e-af11-8e962e939897"
      },
      "source": [
        "change_word(test_1, apostrophe_dict)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thanks for #lyft credit i cannot use cause they do not offer wheelchair vans in pdx. #disapointed #getthanked'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WuEN71ldlsR"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: change_word(x, apostrophe_dict))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y6qdOWWfBDC"
      },
      "source": [
        "4) Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV5QMOGDe8fM"
      },
      "source": [
        "short_word_dict = {\n",
        "\"121\": \"one to one\",\n",
        "\"a/s/l\": \"age, sex, location\",\n",
        "\"adn\": \"any day now\",\n",
        "\"afaik\": \"as far as I know\",\n",
        "\"afk\": \"away from keyboard\",\n",
        "\"aight\": \"alright\",\n",
        "\"alol\": \"actually laughing out loud\",\n",
        "\"b4\": \"before\",\n",
        "\"b4n\": \"bye for now\",\n",
        "\"bak\": \"back at the keyboard\",\n",
        "\"bf\": \"boyfriend\",\n",
        "\"bff\": \"best friends forever\",\n",
        "\"bfn\": \"bye for now\",\n",
        "\"bg\": \"big grin\",\n",
        "\"bta\": \"but then again\",\n",
        "\"btw\": \"by the way\",\n",
        "\"cid\": \"crying in disgrace\",\n",
        "\"cnp\": \"continued in my next post\",\n",
        "\"cp\": \"chat post\",\n",
        "\"cu\": \"see you\",\n",
        "\"cul\": \"see you later\",\n",
        "\"cul8r\": \"see you later\",\n",
        "\"cya\": \"bye\",\n",
        "\"cyo\": \"see you online\",\n",
        "\"dbau\": \"doing business as usual\",\n",
        "\"fud\": \"fear, uncertainty, and doubt\",\n",
        "\"fwiw\": \"for what it's worth\",\n",
        "\"fyi\": \"for your information\",\n",
        "\"g\": \"grin\",\n",
        "\"g2g\": \"got to go\",\n",
        "\"ga\": \"go ahead\",\n",
        "\"gal\": \"get a life\",\n",
        "\"gf\": \"girlfriend\",\n",
        "\"gfn\": \"gone for now\",\n",
        "\"gmbo\": \"giggling my butt off\",\n",
        "\"gmta\": \"great minds think alike\",\n",
        "\"h8\": \"hate\",\n",
        "\"hagn\": \"have a good night\",\n",
        "\"hdop\": \"help delete online predators\",\n",
        "\"hhis\": \"hanging head in shame\",\n",
        "\"iac\": \"in any case\",\n",
        "\"ianal\": \"I am not a lawyer\",\n",
        "\"ic\": \"I see\",\n",
        "\"idk\": \"I don't know\",\n",
        "\"imao\": \"in my arrogant opinion\",\n",
        "\"imnsho\": \"in my not so humble opinion\",\n",
        "\"imo\": \"in my opinion\",\n",
        "\"iow\": \"in other words\",\n",
        "\"ipn\": \"I’m posting naked\",\n",
        "\"irl\": \"in real life\",\n",
        "\"jk\": \"just kidding\",\n",
        "\"l8r\": \"later\",\n",
        "\"ld\": \"later, dude\",\n",
        "\"ldr\": \"long distance relationship\",\n",
        "\"llta\": \"lots and lots of thunderous applause\",\n",
        "\"lmao\": \"laugh my ass off\",\n",
        "\"lmirl\": \"let's meet in real life\",\n",
        "\"lol\": \"laugh out loud\",\n",
        "\"ltr\": \"longterm relationship\",\n",
        "\"lulab\": \"love you like a brother\",\n",
        "\"lulas\": \"love you like a sister\",\n",
        "\"luv\": \"love\",\n",
        "\"m/f\": \"male or female\",\n",
        "\"m8\": \"mate\",\n",
        "\"milf\": \"mother I would like to fuck\",\n",
        "\"oll\": \"online love\",\n",
        "\"omg\": \"oh my god\",\n",
        "\"otoh\": \"on the other hand\",\n",
        "\"pir\": \"parent in room\",\n",
        "\"ppl\": \"people\",\n",
        "\"r\": \"are\",\n",
        "\"rofl\": \"roll on the floor laughing\",\n",
        "\"rpg\": \"role playing games\",\n",
        "\"ru\": \"are you\",\n",
        "\"shid\": \"slaps head in disgust\",\n",
        "\"somy\": \"sick of me yet\",\n",
        "\"sot\": \"short of time\",\n",
        "\"thanx\": \"thanks\",\n",
        "\"thx\": \"thanks\",\n",
        "\"ttyl\": \"talk to you later\",\n",
        "\"u\": \"you\",\n",
        "\"ur\": \"you are\",\n",
        "\"uw\": \"you’re welcome\",\n",
        "\"wb\": \"welcome back\",\n",
        "\"wfm\": \"works for me\",\n",
        "\"wibni\": \"wouldn't it be nice if\",\n",
        "\"wtf\": \"what the fuck\",\n",
        "\"wtg\": \"way to go\",\n",
        "\"wtgp\": \"want to go private\",\n",
        "\"ym\": \"young man\",\n",
        "\"gr8\": \"great\"\n",
        "}\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcg3EkSnfG9L"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: change_word(x, short_word_dict))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8XrjL-xfPOM"
      },
      "source": [
        "5) Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s18NqRf8fR8J"
      },
      "source": [
        "emoticon_dict = {\n",
        "\":)\": \"happy\",\n",
        "\":‑)\": \"happy\",\n",
        "\":-]\": \"happy\",\n",
        "\":-3\": \"happy\",\n",
        "\":->\": \"happy\",\n",
        "\"8-)\": \"happy\",\n",
        "\":-}\": \"happy\",\n",
        "\":o)\": \"happy\",\n",
        "\":c)\": \"happy\",\n",
        "\":^)\": \"happy\",\n",
        "\"=]\": \"happy\",\n",
        "\"=)\": \"happy\",\n",
        "\"<3\": \"happy\",\n",
        "\":-(\": \"sad\",\n",
        "\":(\": \"sad\",\n",
        "\":c\": \"sad\",\n",
        "\":<\": \"sad\",\n",
        "\":[\": \"sad\",\n",
        "\">:[\": \"sad\",\n",
        "\":{\": \"sad\",\n",
        "\">:(\": \"sad\",\n",
        "\":-c\": \"sad\",\n",
        "\":-< \": \"sad\",\n",
        "\":-[\": \"sad\",\n",
        "\":-||\": \"sad\"\n",
        "}"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWcBX0fmfLaC"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: change_word(x, emoticon_dict))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwAWFeSjf3ZX"
      },
      "source": [
        "6) Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUYPUH2flIPl"
      },
      "source": [
        "import string\n",
        "\n",
        "remove = string.punctuation\n",
        "pattern = r\"[{}]\".format(remove) "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDk6-a4WfVK7"
      },
      "source": [
        "# change to space\n",
        "def to_space(pattern_:str, x:str, to_:str=' '):\n",
        "    # to_space = re.findall(pattern, x)\n",
        "    x = re.sub(pattern, to_, x)\n",
        "    return x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "vc06QPM8itQm",
        "outputId": "63c47a10-045d-42d1-e995-9211e344cf43"
      },
      "source": [
        "test_2 = combine_df.tweet[1]\n",
        "test_2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thanks for #lyft credit i cannot use cause they do not offer wheelchair vans in pdx. #disapointed #getthanked'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wo2svuWJi0kd",
        "outputId": "63ae5f12-f5fd-4cd7-a0bd-9c7b13d81331"
      },
      "source": [
        "to_space(pattern_=pattern, x=test_2, to_=' ')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thanks for  lyft credit i cannot use cause they do not offer wheelchair vans in pdx   disapointed  getthanked'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DhjjsTHpMt-"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: to_space(pattern_=pattern, x=x, to_=' '))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5SayimhjAGV"
      },
      "source": [
        "# 1? Почему когда делаешь цикл как в первом задании, в результате получаешь точки?"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7W7LR_ToqEJ"
      },
      "source": [
        "7) Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e01mL91SoRni"
      },
      "source": [
        "# 2? Почему петтер для слов и цифр а надо спец. символы заменить?\n",
        "# 3? По идее решено выше?"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJAzHb6uo-rA"
      },
      "source": [
        "8) Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ZtRh6d64o9ED",
        "outputId": "23085bf5-84f0-4f25-8e24-16f47f7c3a50"
      },
      "source": [
        "test_1 = combine_df.tweet[5]\n",
        "test_1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 2 2  huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "wvJ7oVCto598",
        "outputId": "aff86ca2-bc2f-4b44-917c-b39200a23b06"
      },
      "source": [
        "to_space(pattern_= r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", x=test_1, to_=' ')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 2 2  huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb947nyJpjY7",
        "outputId": "dcc1bfdb-b863-4e90-af1f-d472aac49631"
      },
      "source": [
        "re.findall(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", test_1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' ', '2'), (' ', '2')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0xlksAHrWyq",
        "outputId": "e92a51f2-1d40-4ac3-cc3b-4e26b15de515"
      },
      "source": [
        "re.findall(r\"\\d\", test_1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2', '2']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "8dPdf350rl7K",
        "outputId": "fa476cf9-5922-4a00-c008-fc601cba0ee6"
      },
      "source": [
        "to_space(pattern_= r\"\\d\", x=test_1, to_=' ')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 2 2  huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "3TU7kaHSrr2d",
        "outputId": "df630f5d-8ff4-456b-ddbd-cb4ac7345611"
      },
      "source": [
        "re.sub('\\d', '', test_1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'    huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naETCRMCn9sQ"
      },
      "source": [
        "# 4?  Почему код функции to_space отрабатывает не корректно ? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdbVUR7En2_i"
      },
      "source": [
        "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DBV_wksr2h-"
      },
      "source": [
        "combine_df.tweet = combine_df.tweet.apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW4-hBphoc_t"
      },
      "source": [
        "\n",
        "10) Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pqGjh8soahR",
        "outputId": "fe36e162-9b5b-4b87-f83a-5f691ca6c5d0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99LkV4liom_n"
      },
      "source": [
        "combine_df['tweet_token'] = 0\n",
        "combine_df.tweet_token = combine_df.tweet.apply(lambda x: nltk.tokenize.word_tokenize(x))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boJCn9Phozh6"
      },
      "source": [
        "# 5? почему меня вежливо попросили подгрузить nltk.download('punkt')?"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzrZHGSbpYhD"
      },
      "source": [
        "12) Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSSaQNimpW8v"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "combine_df['tweet_stemmed'] = 0\n",
        "combine_df.tweet_stemmed = combine_df.tweet_token.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qysJVDasGXg"
      },
      "source": [
        "13) Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvmo8LsAqWwZ",
        "outputId": "11d44a56-49b6-4ae5-c8be-cf43eeae3b38"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "combine_df['tweet_lemmatized'] = 0\n",
        "combine_df.tweet_lemmatized = combine_df.tweet_token.apply(lambda x: [lemmatizer.lemmatize(i, wordnet.VERB) for i in x])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78In7Lms65E"
      },
      "source": [
        "14) Сохраним результат предобработки в pickle-файл.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dpuey9Ys6Hg"
      },
      "source": [
        "combine_df.to_pickle(\"dummy.pkl\")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "763Xsq9mqkPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}